
\chapter[Darstellung der Grundlagen \anmerkung{30-40 Seiten}]{Darstellung der Grundlagen\\
\normalsize{(nicht selbstgemachtes
Secondo,
MovingRegion,
T\o{}ssebro)}\anmerkung{30-40 Seiten}} \label{Kapitel2}
\minitoc
\newpage
\section{Secondo \anmerkung{10 Seiten}}\label{SecondoEinfuehrung}
\anmerkung{Eine ausf"uhlichere Beschreibung von Secono, speziell des Konzeptes der Algebren, und eine Beschreibung der Algebren ,,Spatial-Algebra'' und ,Moving-Region-Algebra''.}
\subsection{Das Konzept der Secondo-Algebren}
\subsection{Spatial-Algebra}
\subsection{Moving-Region-Algebra}

\section{Das Paper von Erlend T\o{}ssebro \anmerkung{10 Seiten}}\label{Tossebro}

Eine der wichtigsten Grundlagen der vorliegenden Arbeit ist das Paper: ,,Creating Repesentations for Continuously Moving Regions from Observations'' \cite{TG} von Erlend T\o{}ssebro und Ralf Hartmund G"uting \cite{TG}, in dem die Autoren sich mit den theoretischen Grundlagen des Problems besch"aftigt, und L"osungsvorschl"age zu vielen der vorkommenden Teilprobleme gemacht haben.

Im Rahmen dieses Projektes ist auch eine Java-Applikation entstanden, welche im Rahmen meiner Arbeit erweitert wurde.

\subsection{Die zugrundeligenden Datentypen}
Nach der allgemeinen Einleitung skizzierten die Autoren kurz die Datentypen, wie diese in \cite{FGNS} beschrieben sind.

Zuerst die nicht beweglichen Daten:
$$Seg=\{(u,v)|u,v\in Point, u<v\}$$

Ein Segment ist also ein Liniensegment zwischen zwei Punkten. 

$$Cycle=\{S\subset S\}$$

Ein Cycle ist eine Menge von Liniensegmenten, die zusammen ein einfaches Polygon bilden müssen.

$$Face=\{(c,H)|c\in Cycle, H \subset Cycle\}$$

Ein Face setzt sich aus einem Cycle, der äußeren Begrenzungslinie, und einer Menge von anderen Cycles, den Löchern oder Holes zusammen. Jedes Hole muss komplett innerhalb des äußeren Cycles liegen, und zwei Holes dürfen sich nicht überschneiden. 

$$Region=\{F\subset Face|f_1,f_2\in F \wedge (f_1\neq f_2) \Rightarrow \text{Kanten von }f_1\text{ und } f_2 \text{ sind disjunkt. } \}$$

Eine Region schließlich setzt sich aus mehreren Faces zusammen, wobei sich diese nicht überschneiden dürfen. 

Nun skizzieren die Autoren die beweglichen Datentypen:

$$MPoint=\{(x_0,x_1,y_0,y_1)|x_0,x_1,y_0,y_1\in \mathbb{R}\}$$

Ein MovingPoint setzt sich aus zwei Punkten, dem Start- und dem Endpunkt zusammen.

$$MSeg=\{(s,e)|s,e\in MPoint\}$$

Ein MovingSegment setzt sich aus zwei MovingPoints zusammen, wobei aber alle vier beteiligten Start- und Endpunkte auf einer Ebene liegen müssen. Ein wichtiger Sonderfall des MovingSegemnts ist der, wenn beide Start- oder beide End-punkte zusammenfallen. In diesem Fall repräsentiert ein MovingSegment ein Dreick in drei Dimensionen.

$$MCycle=\{(s_0,s_1,\hdots ,s_{n-1})|n\geq3, s_i\in MSeg\}$$

Ein MovingCycle ist die bewegliche Version eines Cycles. Die beteiligten MovingSegemnts müssen zusammen eine geschlossene, dreidimmensionale Struktur bilden.

$$MFace=\{(c,H)|c\in MCycle, H\subset MCycle\}$$

Ein MovingFace ist die dreidimensionale Version eines Faces, und setzt sich analog zu diesem zusammen.

$$URegion=\{(i,F)|i\in Intervall, F\subset MFace\}$$

Eine RegionUnit schließlich besteht aus einer Menge von MovingFaces und einem Zeitintervall. 

Eine MovingRegion schließlich besteht aus mehreren RegionUnits, bei denen die Zeitintervalle paarweise disjunkt sind.

\subsection{Der Rotating-Pane-Algorithmus}

Die Autoren entwickeln einen Algorithmus, mit dessen Hilfe sich MovingCycles aus zwei konvexen Polygonen berechnen lassen. Anschaulich funktioniert dieser Algorithmus wie folgt:

Wähle eine Kante $s$ des einen Polygons, und lasse die Grundebene des Polygons entlang dieser Achse rotieren. Die Ebene wird dann auf das andere Polygon treffen. Trifft die Ebene zuerst auf einen einzigen Punkt $T$, so gehört das Dreick aus den beiden Punkten von $s$ und $T$ zu dem MovingCycle.

Trifft die Ebene aber auf eine Kante $t$, so gehört das MovingSegment von $s$ zu $t$ zu dem MovingCycle.

Dieses Verfahren wende auf alle Kanten aus beiden Polygonen an.

Die Autoren geben auch noch einen Algorithmus an, der diese Idee weiterverfolgt, der aber technisch einfacher zu implementieren ist. Eine leicht veränderte Version dieses Algorithmuses beschreibe ich unter \ref{rotPane} genauer.

Die Autoren geben noch die Laufzeit des Verfahrens an und sagen, dass der Algorithmus zu zwei Polygonen, welche zusammen $n$ Ecken haben, ein MovingCycle berechnet und hierfür $O(n*\log{n})$ Zeit benötigt. Liegen die Punkte der Polygone bereits sortiert vor, so sinkt die Laufzeit auf $O(n)$.

Die Autoren räumen ein, dass dieses Verfahren nicht gut mit Rotationen umgehen kann. Lassen wir etwa zwei dünne Rechteck durch diesen Algorithmus laufen, die um 90\degree gedreht sind, so wird die Interpolation nach der Hälfe der Zeit ungefähr quadratisch  sein und einen zu großen Flächeninhalt aufweisen. Abbildung~\ref{fig:BeispielschlechteRot} zeigt dieses Beispiel. Eine Lösung dieses Problems können die Autoren nicht angeben, bei Rotationen sollten also die Unterschiede zwischen den Schnappschüssen nicht zu groß sein.

\begin{figure}
	\centering
	\includegraphics{feu_logo2.eps}
	\caption{Ein Beispiel in dem man die Schwäche des Verfahrens bei großen Rotationen zeigt.}
	\label{fig:BeispielschlechteRot}
\end{figure}

\subsection{Der Konvexe Hüllenbaum}

Das obige Verfahren kann nur mit konvexen Polygonen umgehen. Um im Allgemeinen einfache Polygone bearbeiten zu können führen die Autoren den ConvexHullTree ein. Die Idee hinter diesen ist es, einfache Polygone als konvexe Polygone mit konvexen Löchern aufzufassen. 

Ein ConvexHullTreeNode ist ein konvexes Polygon, bei dem jeder Kante wiederum ein ConvexHullTreeNode zugeordnet werden kann. Diese Kinderelemente werden von dem Vaterelement abgezogen. Abbildung~\ref{fig:ConHullTree} zeigt einen solches Konstrukt.

\begin{figure}
	\centering
	\includegraphics{feu_logo2.eps}
	\caption{Ein Beispiel für einen ConvexHullTree.}
	\label{fig:ConHullTree}
\end{figure}

Die Autoren beschreiben, wie man einen solchen Baum aufbaut. Dieses Verfahren ist näher unter \ref{constCHTN} beschrieben.

Die Komplexität der Konstuktion eines Hüllenbaumes wird mit $O(dn*\log(n))$ angegeben, wobei $d$ die Tiefe des resultierenden Baumes ist.

Der umgekehrte Weg, also aus einem ConvexHullTee wieder ein Polygon zu erzeugen funktioniert so:

\begin{itemize}
\item Gebe jedes Segment zurück, für das es kein Kindelement gibt.
\item Für jedes Segment, welches ein Kindelement hat benutze diese Funktion rekursiv.
\end{itemize}

\subsection{Matching zweier Regionen}

Im Weiteren beschäftigen sich die Autoren mit der Frage, wie man zu gegebenen Polygonen, welche die beiden Schnappschüsse einer MovingRegion darstellen sollen, ein Match bestimmen kann. Ein Match ist eine Menge von Paaren von Cyclen, die zusammengehören.

Die Autoren unterscheiden drei unterschiedliche Arten von Matches:

\begin{itemize}
\item Wenn beide Regionen aus mehreren Faces zusammengesetzt sind, welche Faces auf der einen Seite passen dann zu welchen Faces auf der anderen Seite?
\item Falls ein Face mehrere Holes hat, welches Hole auf der einen Seite passt dann zu welchem Hole auf der anderen Seite?
\item Hat ein Cycle mehrere Konkativitäten, welche Konkativitäten auf der einen Seite passen dann zu welchen Konkavitäten auf der anseren Seite?
\end{itemize}

In all diesen Fällen ist auch noch zu beachten, dass einzelne Objekte verschwienden können, oder das mehrere auf der einen Seite zu einem Objekt auf der anderen Seite verschmelzen können.

Um die Qualität eines Matches bestimmen zu können, geben die Autoren einige Kriterien an:

\begin{enumerate}
\item Ein matching-Verfahren sollte das korrekte Ergebnis liefern, falls beide Schnappschüsse übereinstimmen.
\item Komponenten, die sich relativ zu ihrer Größe wenig bewegt haben, sollten korrekt gematcht werden können.
\item Komponenten die nur kleine Änderungen an Größe und Form erfahren haben sollten korrekt gematcht werden.
\item Ein Matching-Verfahren sollte Komponenten erkennen, die sich in mehrere neue aufgesplittet haben, oder solche die sich vereinigen.
\item Ein Matching-Verfahren sollte Kriterien anbieten um zu entscheiden, ob zwei Momentaufnahmen gut zueinander passen, oder ob der zeitliche Abstand zwischen diesen zu groß gewählt ist.
\end{enumerate}

Die Autoren führen den Begriff des ,,sicheren'' Matches an:

Sei $mr$ eine MovingRegion und seien $S_1$ und $S_2$ zwei Schnappschüsse dieser MRegion zu den Zeitpunkten $t$ und $t+\Delta t$. Ein Matching-Verfahren ist sicher zu nennen, falls es ein $\epsilon >0$ gibt, so dass das Match korrekte Ergebnisse liefert, für alle $\Delta t < \epsilon$.

Die Autoren finden drei verschiedene Matching-Strategien, die im folgenden kurz aufgef"uhrt werden:
\begin{enumerate}
\item Position of centroid \label{MatchSchwer}

Bestimme den Schwerpunkt jedes Cycles,  bilde aus diesem einen gewichteten Graphen, mit den Entfernungen als Kantengewichte und suche in diesem "`N"achste Nachbarn"'.
\item Fixed threshold (set of cycles)

Matche zwei Cycles, wenn sie sich wechselseitig  mehr als threshold (in \%) "uberlappen.

\item Maximize Overlap (set of cycles)

Bilde einen gewichteten Graphen, in dem die Cycles Knoten sind, und dessen Kanten mit dem Grad der "Uberlappung gewichtet sind. Matche dann ein Cycle $c$ mit demjenigen, mit dem er die gr"o"ste "Uberlappung aufweist, und mit allen, f"ur die $c$ der Cycle mit der gr"o"sten "Uberlappung ist.
\end{enumerate} 

Die Autoren kommen zu dem Schluß, dass das Schwerpunktverfahren kein sicheres Verfahren sei, da der Schwerpunkt eines Polygones außerhalb dieses liegen kann.

Im weiteren Verlauf betrachten die Autoren nur noch einzelne Cycles, Betrachtungen von Faces und Regions werden nicht mehr angestellt.

\subsection{Interpolation zwischen zwei ConvexHullTrees}

Nun beschäftigen sich die Autoren damit, einen Algorithmus zu erarbeiten, mit dessen Hilfe sich eine Interpolation zwischen zwei einfachen Polygonen berechnen lassen. Dieser Algorithmus beruht darauf, den Rotating-Pane-Algorithmus für alle konvexen Hüllen duchlaufen zu lassen, und hierbei die Darstellung des Polygones als ConvexHullTree zu benutzen.

Gegeben seien also zwei einfache Polygone, $A$ und $B$, dargestellt als ConvexHullTrees. Das Matching zwischen diesen sei berechnet, so dass man für alle Elemente von $A$ bestimmen kann, welche Elemente von $B$ dazu passen.

Wir nehmen an, dass $A$ auf $B$ gematcht wird, und berechen für die konvexen Hüllen von $A$ und $B$ die MSegments mit dem  Rotating-Pane. 

Nehmen wir nun an, dass eine Konkativität von $A$ keiner Konkativität von $B$ zugeordnet wird. Die Punkte, an denen diese Konkativität die konvexe Hülle des Vater berührt, nenn wir $p$ und $e$. In diesem Fall bestimmen wir das MSegment aus den bereits Berechneten, dass $p$ und $e$ enthält. Diesem MSegment, dessen dritten Punkt wir $t$ nennen, löschen wir. Falls dieses MSegement kein Dreieck ist, so müssen wir dieses zuerst in zwei Dreicke spalten. Nun bilden wir für alle Kanten der konvexen Hülle der Konkativität, außer $pe$, MSegmente mit dem Punkt $t$ und fügen diese dem Ergebnis hinzu.

Wird eine Konkativität von $A$ gegen eine Konkativität von $B$ gematcht, so bilden wir mittels Rotating-Pane die MSegmente zwischen diesen und fügen sie der Ergebnisliste an. In dieser Liste werden jetzt zwei oder vier paarweise gleiche MSegmente vorkommen\footnote{Bei der praktischen Anwendung dieses Algorithmuses zeigte sich, dass dies durchaus nicht immer der Fall ist. Außnahmen diskutiere ich unter \ref{gedrehtKon}.}. Diese Segmente, die die Schnittstelle zwischen den Vater- und Kind konvexer-Hülle bilden, werden alle gelöscht. 

Der dritte, kompliziertest Fall tritt dann auf, wenn mehrere Konkativitäten auf der einen Seite zu Einer auf der anderen Seite verschmelzen. Für diesen Fall erarbeiten die Autoren einen Algorithmus, der darauf beruht, von den mehreren Konkativitäten die konvexe Hülle zu berechnen und diese auf die eine Konkativität der anderen Seite zu matchen. Damit das Verfahren danach weiterlaufen kann, wird der ConvexHullTree uaf der mehrdeutigen Seite umgebaut, so dass die Kinder der Konkativitäten geeignet an die neue konvexe Hülle gehängt werden\footnote{Leider funktionert dieses Verfahren nicht in allen Fällen. Unter \ref{JoinConc} diskutiere ich dieses Verhalten näher.}.

\section[Matching Shapes with a Reference Point]{Das Paper: ,,Matching Shapes with a Reference Point'' }\label{AARR}

Als eine sehr interessante Quelle erwieß sich das Paper \cite{AAR}, dessen Inhalt ich hier kurz wiedergeben möchte:

\subsection{Einleitung}

In ihrer Arbeit betrachten die Autoren Ähnlichkeiten von Objekten, die als Punktmengen repäsentiert werden. Diese Betrachtungen haben besondere Relevanz in Anwendungen der Mustererkennung. Als Maß für die Ähnlichkeit von zwei Objekten wird hier, wie auch in den meisten anderen Arbeiten zu diesen Themen, der Hausdorff-Abstand\index{Hausdorff-Abstand!als Norm} benutzt, den ich unter \ref{Hausdorff} näher beschreibe.

Um die Ähnlichkeit von zwei Objekten: $A$ und $B$ aus $\mathbb{R}^2$ oder aus $\mathbb{R}^3$ zu bestimmen, reicht es nicht den Hausdorff-Abstand $\delta_H(A,B)$ zu bestimmen, sondern man sucht die Abbildung $T\in\mathcal{T}$ unter der $\delta_H(A,T(B))$ minimal ist. $\mathcal{T}$ ist hierbei die Menge aller ,,erlaubten'' Abbildungen. Solche Abbildungen sind üblicherweise Rotationen, Verschiebungen, Skallierungen und Kombinationen aus solchen. Also sucht man:

$$\min_{T\in\mathcal{T}}\delta_H(A,T(B))$$

Die Suche nach dem optimalen $T$ ist im allgemeinen sehr kompliziert und aufwendig. Desshalb versuchen die Autoren keine optimale Abbildung $T_{OPT}$ zu finden, sondern sie suchen nach einer einfach und schnell berechenbaren Näherung, also einer Abbildung $T_{Approx}$, die $T_{OPT}$ zuverlässig und gut annähert.

\subsection{\index{Match!pseudooptimales}Das pseudooptimale Match}

Die Autoren definieren eine solche Abbildung als ,,pseudooptimales-Match mit Fehlerfaktor $\alpha$'' ( $\alpha\geq 1$, $\delta$ ist der optimale Hausdorff-Abstand)

$$\delta_H(A,T(B))\leq \alpha \delta$$

\subsection{\index{Referenzpunkt!Definition}Die Definition des Refenenzpunktes}

Der Versuch ein solches pseudo-optimales Matching zu finden unternehmen die Autoren über Referenzpunkte. Als $\mathcal{T}$ respektierenden Referenzpunkt definieren sie eine Abbildung $s:C_d\longrightarrow\mathbb{R}^d$, für die gilt:
$$\forall A, B\in C^d \text{ und } \forall T\in\mathcal{T}\Rightarrow$$
$$s(T(A))=T(s(A))\text{ (s ist äquivariant) und}$$
$$\exists c\geq0 \text{, so dass } \forall A, B \in C^d\Rightarrow$$
$$\Vert s(A)-s(B)\Vert\leq c\times\delta_H(A,B)\text{ (s ist Lipschitz-stetig mit Konstante c)}.$$

$c$ nennen die Autoren auch die Qualität von $s$.

\subsection{Algorithmen zum Finden von pseudooptimalen Lösungen}

Unter der Annahme, dass das ein solcher Referenzpunkt gefunden wurde, entwickeln die Autoren drei Algorithmen:
\begin{itemize}
\item Algorithmus $T$
\begin{enumerate}
\item Berechne $s(A)$ und $s(B)$.
\item Die pseudooptimale Lösung ist die Verschiebung um den Vektor $s(A)-s(B)$. Das Bild von $B$ nenne $B'$
\end{enumerate}

\item Algorithmus $R$
\begin{enumerate}
\item Wie in $T$.
\item Finde die optimale Rotation von $B'$ um $s(A)$. Diese Rotation, verknüpft mit der Verschiebung aus $T$, ist die pseudooptimale Lösung. Das Bild dieser nenne im Weiteren $B''$.

\end{enumerate}
\item Algorithmus $S$
\begin{enumerate}
\item Wie in $R$.
\item Bestimme die Durchmesser $d(A)$ und $d(B)$ und skalliere $B'$ um den Faktor $\alpha =\frac{d(A)}{d(B)}$.
\item Wie Schritt 2 in $R$ 
\end{enumerate}
\end{itemize}

Dann beweisen die Autoren:
\begin{enumerate}
\item Algorithmus $T$ findet eine pseudooptimale Abbildung für Verschiebungen. Der Verlustfaktor ist $\alpha=c+1$
\item Algorithmus $R$ findet eine pseudooptimale Abbildung für Kompositionen aus Verschiebungen und Rotationen.  Der Verlustfaktor ist $\alpha=c+1$
\item Algorithmus $S$ findet eine pseudooptimale Abbildung für Kompositionen aus Verschiebungen, Rotationen und Skallierungen. Der Verlustfaktor ist $\alpha=c+3$
\end{enumerate}

\subsection{\index{Referenzpunkt!SteinerPunkt}\index{Steinerpunkt!als Referenzpunkt}Die Wahl des richtigen Referenzpunktes}

Im weiteren Verlauf werden verschiedene Referenzpunkte untersucht. Der Schwerpunkt der konvexen Hüllen ist ein Referenzpunkt mit der Qualität $c=4\pi+3$. Der beste Referenzpunkt, den die Autoren finden konnten ist der Steinerpunkt, den ich in \ref{Steinerpunkt} beschreibe. Die Autoren zeigen, dass der Steinerpunkt ein Referenzpunkt für alle untersuchten Abbildungen ist und zeigen, dass dessen Qualität im zweidimensionalen $c=\frac{4}{\pi}$ ist. 

\subsection{Untere Schranke für die Qualitäten von Referenzpunkten}

Zuletzt finden die Autoren eine untere Schranke für die Qualität eines Referenzpunktes im Zweidimensionalen, unter Verschiebungen. Die Qualität eines Referenzpunktes unter diesen Abbildungen kann nicht besser sein als $\sqrt{\frac{4}{3}}$. Diese Behauptung wird bewiesen. 

Vergleicht man die Qualität des Steinerpunkts ($\frac{4}{\pi}\thickapprox 1,155$) mit diesem theoretischen minimalen Wert ($\sqrt{\frac{4}{3}}\thickapprox 1,27$), so stellt man fest, dass der Abstand der Qualitäten sehr gering ist. Der Steienerpunkt ist also warscheinlich der beste mögliche Referenzpunkt (für die Norm ,,Hausdorff-Abstand'').

\subsection{Die Bedeutung für meine Arbeit}\label{BedeutungAAR}

Zwar habe ich dieses Matching nicht so implementiert, wie es hier beschrieben wurde, ich habe aber ein Match programmiert, dass simultan zu dem Schwerpunkt-Match mit Schwellenwert von Herr T\o{}ssebro (siehe \ref{MatchSchwer}) funktioniert, nur dass hierbei der Schwerpunkt durch der Steinerpunkt ersetzt wird.

Betrachtet man sich den T\o{}ssebroschen Algorithmus, so stellt man fest, dass dieser starke Ähnlichkeit zu dem Algorithmus $R$ aus diesem Paper aufweist. Es steht also zu erwarten, dass dieser Algorithmus Matches finden wird, die gute Ergebnisse bezüglich des Hausdorff-Abstands liefern werden. Die hier beschriebenen Algorithmen konkret umzusetzen wäre eventuell eine gute Idee, die aber über den Umfang dieser Arbeit hinausgeht.

\section[Matching Shapes with Symmetric Difference]{Das Paper: ,,Matching Convex Shapes with Respect to Symmetric Difference'' }\label{AFRWW}
\anmerkung{Hier gebe ich eine Inhaltsangabe des Papers, und gehe speziell auf die Auswirkungen ein, die diese auf meine Matchingideen haben.}

Als eine weitere sehr interesannte Quelle erwies sich die Arbeit \cite{AFRW}, die stark auf der Anderen aufbaut. Auch von diesem Werk werde ich zunächst kurz den Inhalt wiedergeben.

\subsection{Die Grundlagen}

Zunächst klären die Autoren die Grundlagen dieser Arbeit. Da dieses Paper auf \cite{AAR} aufbaut, sind diese Grundlagen bereits aus dieser Arbeit bekannt. 

\subsection{\index{symmetrische Differenz!als Norm}Die symmetrische Differenz als Norm}

Als neue Norm für die Ähnlichkeit von zwei Objekten wird die \textbf{symmetrische Differenz} beschrieben. Diese ist unter  \ref{symDiff} näher beschrieben. Die Autoren machen darauf aufmerksam, dass diese Norm ein gutmütigeres Verhalten an den Tag legt, wenn die zu matchenden Polygone ,,gestört'' sind. Gestört soll in diesem Zusammenhang heißen, dass an sich an dem Rand des eigentlichen Polygon schmale, lange Dreiecke befinden. Unter \ref{symDiff} erläutere ich auch diesen Zusammenhang näher.

\subsection{\index{Schwerpunkt!als Referenzpunkt}\index{Referenzpunkt!Schwerpunkt}Der Schwerpunkt als Referenzpunkt für Verschiebungen}

Als Referenzpunkt für Abbildungen unter dieser Norm wird der Schwerpunkt der Polygone betrachtet. Dieser wird in dem Paper  nicht näher erläutert, ich beschreibe ihn trotzdem unter \ref{Schwerp}. 

Für $A, B \in \mathbb{R}^2$ und $\mathcal{T}$ die Menge der Verschiebungen wird der Satz

$$\delta_C (A,\tilde{T}(B))\leq\frac{11}{3}\min_{T\in\mathcal{T}}\delta_C(A,T(B))$$


aufgestellt und bewiesen. $\tilde{T}$ ist hierbei diejenige Verschiebung, die den Schwerpunkt von $B$ auf den Schwerpunkt von $A$ abbildet.

\subsection{allgemeinere Abbildungen}

Um diesen Referenzpunkt auch auf andere Abbildungen anwenden zu können, wird der Satz aufgestellt und bewiesen:

Gilt für eine Menge $\mathcal{T}$  von Abbildungen 
\begin{enumerate}
\item $s(T(A))=T(s(B))$ für $T\in\mathcal{T}$ und 
\item $\mathcal{T}$ ist abgeschlossen bezüglich der Kompsition von Abbildungen.
\end{enumerate}
dann ist der Schwerpunkt ein $\mathcal{T}$ respektierender Referenzpunkt mit Qualität $\frac{11}{3}$.

Abbildungen, die diese Bedingung erfüllen sind: 
\begin{itemize}
\item Kombinationen aus Verschiebungen und Rotationen,
\item Kombinationen aus Verschiebungen und Skallierungen,
\item Kombinationen aus allen drei Abbildungsarten und
\item belibige affine Abbildungen.
\end{itemize}

\subsection{Algorithmen zum Finden von pseudooptimalen Lösungen}

Nun erarbeiten die Autoren verschiedene Algorithmen, um Matchings für die verschiedenen Abbildungsarten durchführen zu können:
\begin{enumerate}
\item Verschiebungen

Verschiebt man $B$ um den Vektor $s(B)-s(A)$ auf $B'$, so hat man ein pseudooptimales Matching gefunden. Dieser Algorithmus entspricht dem Algorithmus $R$ aus dem letzten Abschnitt.

\item Kombinationen von Verschiebungen und Skallierungen

Verschiebt man zunächst $B$ wie oben angegeben, und skalliert dann $B'$ an dem Fixpunkt $s(A)$ um den Faktor $\lambda$, so hat man ein pseudooptimales Matching gefunden. $\lambda$ ist hierbei der Faktor, bei dem dem $\delta_C(A,\lambda B')$ minimal ist. Dieser Faktor kann in Linearzeit berechnet werden, wie die Autoren zeigen.

\item Kombinationen aus Verschiebungen und Rotationen

Auch hier wird zunächt $B'$ duch Verschiebung, wie oben, gebildet. Nun wird der Winkel $\varphi$ gesucht, für den $\delta_C(A,t_\varphi( B'))$ minimal ist. $t_\varphi$ sei die Rotations-Abbildung um den Punkt $s(A)$. Eine wirklich effiziente Lösung dieses Problems können die Autoren leider nicht geben, so dass man leider keinen effizienten Algorithmus für Abbildungen angeben kann, die Rotationen enthalten. 
\end{enumerate}

\subsection{Fazit}

Falls man die symmetrische Differenz als Norm benutzt, kann man  zusammenfassend sagen:
\begin{itemize}
\item Schwerpunkte sind Referenzpunkte für alle relevanten Abbildungen und
\item das Matching auf dieser Grundlage für alle Kombinationen aus Verschiebungen und Skallierungen ein pseudooptimales Matching mit der Qualität $\frac{11}{3}$ liefert. 
\end{itemize} 
\subsection{Die Bedeutung für meine Arbeit}\label{BedeutungAFRW}

Ein Matching, dass den Schwerpunkt als Referenzpunkt benutz hat, ist ebenso bereits in der Arbeit von Erlend T\o{}ssebro enthalten, wie auch ein Matching, dass die Überlappung, also das Inversse der symmetrischen Differenz, benutzt. Zwar sind dessen Algorthmen, wie auch bei der verhergegangenen Arbeit, nicht so ausgefeilt, wie die Algorithemen dieses Papers, aber nach der Lektüre dieser Arbeit kommt schon der Verdacht auf, dass die Resultate des Schwerpunkt-Matchings und die des Überlappungs-Matchings starke Ähnlichkeiten aufweisen werden. 

\section{Grundlagen der Paper}
In den oben beschriebenen Papern wurden einige wichtige, allgemeingültige Begriffe eingeführt. Die Definition dieser wichtigen Begriffe nehme ich erst an dieser Stelle vor, um das Nachschlagen zu erleichtern.

\subsection{\index{Hausdorff-Abstand!Definition und Berechnung}Hausdorff-Abstand}\label{Hausdorff} 

Seien $A$ und $B$ zwei kompakte Teilmengen des $\mathbb{R}^2$ und sei $\Vert\centerdot\Vert$ die Euklidische Norm.
Dann definieren wir eine Hilfsfunktion $ \widetilde{\delta_H}  $, den einseitige Hausdoff-Abstand, wie folgt:
\[ \widetilde{\delta_H}(A,B):=\max_{a\in A} \;\min_{b\in B} \Vert a-b \Vert\]
Der einseitige Hausdorff-Abstand von Polygon $A$ zu Polygon $B$ ist so definiert, dass er der Abstand des am weitesten entfernten Punktes aus $A$ zu dem im am n"achsten gelegenen Punkt aus $B$ ist.  Im weiteren Schritt wird der Hausdorff-Abstand wie folgt definiert: 
\[\delta_H:=\max\{\widetilde{\delta_H}(A,B),\widetilde{\delta_H}(B,A)\}.\]
\begin{figure}
	\centering
	\includegraphics[scale=.6]{Hausdorff.eps}
	\caption[Der Hausdorff-Abstand zweier Polygone]{Der Hausdorff-Abstand zweier Polygone (grün und blau) ist das Paar mit dem größten Abstand (rot) unter allen Paaren, wie beschrieben (schwarz).}
	\label{fig:HausdorffAbstand}
\end{figure}
Nimmt man also von zwei Polygonen zu jedem Punkt der einen Menge den nächsten Punkt der anderen Menge, und umgekehrt und sucht dann das Paar mit dem größten Abstan, so ist dieser der Hausdorff-Abstand.



\subsection{\index{symmetrische Differenz!Definition}Die symmetrische Differenz}\label{symDiff}
\begin{figure}
	\centering
	\includegraphics[scale=.6]{SymDiff.eps}
	\caption[Die symmetrische Differenz zweier Polygone]{Die symetriche Differenz der beiden Polygone aus dem Schaubild \ref{fig:HausdorffAbstand} ist der Flächeninhalt der roten Fläche.}
	\label{fig:SymDiffBild}
\end{figure}

In \cite{AFRW} wird vorgeschlagen den Fl"acheninhalt der symmetrischen Differenz als Abstands-Ma"s zweier konvexer Polygone zu benutzen. Die Symmetrische Differenz von zwei kompakten Teilmengen $A$ und $B$ des $\mathbb{R}^2 $ ist definiert als:
\[A\bigtriangleup B:=(A\setminus B)\cup(B\setminus A).\]
Wenn $A(\cdot)$ der Fl"acheninhalt ist, so bildet $\delta_S$ den Abstand nach der symmetrischen Differenz:
\[\delta_S:=A(A \bigtriangleup B).\]
in \cite{TG} schlagen die Autoren vor, die Überlappung $A\cap B$ als Maß für die Qualität eines Matchings zu benutzen. Wegen:
$$|A\bigtriangleup B|+|A\cap B|=|A\cup B|$$
ist klar, dass ein Match, dass die symmetrische Differenz minimiert,zu dem selben Ergebniss kommen wird, wie ein Match, dass die Überlappung maximiert.

In \cite{AFRW} wurde beschrieben, dass das Verhalten der symmetrischen Differenz relativ ,,gutmütig'' im Bezug auf gestörte Daten sei. Die Zeichnung \ref{fig:VergleichMetrik} erläutert diesen Zusammenhang. Die beiden Polygone sehen den Polygonen aus den Bildern \ref{fig:HausdorffAbstand} und \ref{fig:SymDiffBild} recht ähnlich, nur zwei Punke sind jedem Polygon ergäntzt worden. Dennoch ist der Hausdorf-Abstand um 100\% gestiegen, die Fläche der symmetrischen Differenz hingegen nur etwa um 8\%.

\begin{figure}
	\centering
	\includegraphics[scale=.6]{Metrikengestoert.eps}
	\caption{Hausdorff-Abstand und symmetrische Differenz im Vergleich}
	\label{fig:VergleichMetrik}
\end{figure}


\subsection{\index{Steinerpunkt!Definition}Der Steinerpunkt}\label{Steinerpunkt}

In \cite{Sch} wird der Steinerpunkt beschrieben "`als Schwerpunkt der Massenverteilung, die bei einem konvexen Polygon duch Belegung der Ecken mit den "au"seren Winkeln als Massen [...] gegeben ist"'. Folglich kann der Steiner-Punkt eines konvexen Polygones $P$, das aus den $n$ Eckpunkten $v_i$ besteht, berechnet werden ($\alpha_i$ ist hierbei der Innenwinkel von $v_i$) durch:
\[p_2(P)=\sum^n_{i=1}v_i (\pi-\alpha_i).\]
In der Zeichnung \ref{fig:Referenzpunkte} ist der Steienerpunkt grün eingezeichnet.


\subsection{\index{Schwerpunkt!Definition}Der Schwerpunkt}\label{Schwerp}

Der Schwerpunkt eines Polygones ist der Schwerpunkt der Massenverteilung, die entsteht, wenn man allen Eckpunkten die selbe Masse zuordnet. Er berechnet sich f"ur ein Polygon $P$ mit $n$ Eckpunkten $v_i$:
\[p_0(P)=\sum^n_{i=1}v_i \frac{1}{n}.\]
In der Zeichnung \ref{fig:Referenzpunkte} ist der Schwerpunkt mit roter Farbe markiert. 

Vergleicht man die beiden Referenzpunkte, so kann man sehen, dass der Schwerpunkt etwas ,,träger'' auf Punkte reagiert, die sich stark von den anderen unterscheiden (in dem dargestellten Beispiel der Punkt ganz rechts). In einem regelmäßigen n-Eck stimmen entsprechend beide Referenzpunkte überein. Vergleicht man dieses Verhalten der Referenzpunkt mit dem Verhalten der Normen für gestörte Werte (siehe Abbildung \ref{fig:VergleichMetrik}), so erscheint der Zusammenhang vom ,,empfindlicheren'' Hausdorff-Abstand und dem  Steinerpunkt, sowie der Zusammenhang zwischen den beiden ,,Gutmütigeren'' plausibel.

\begin{figure}
	\centering
	\includegraphics[scale=.8]{Referenzpunkte.eps}
	\caption[Vergleich beider Referenzpunkte]{Hier kann man beide Referenzpunkte im Vergleich sehen (der Schwerpunkt der Massenverteilung ist rot, der Steinerpunkt grün) }
	\label{fig:Referenzpunkte}
\end{figure}


