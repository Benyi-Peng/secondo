\documentclass[a4paper,11pt]{scrreprt}

\usepackage{ngerman}
\usepackage[T1]{fontenc}
\usepackage{fancyheadings}


\renewcommand{\labelenumi}{\theenumi)}
\renewcommand{\labelenumii}{(\alph{enumii})}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{eufrak} 
\usepackage{index}
  \newindex{default}{idx}{ind}{Schlagwortverzeichnis}
\usepackage{bibgerm}
%opening
\title{Ideen zum Matching}
\author{Andreas Ruloffs}

\begin{document}

\maketitle

\begin{abstract}
In diesem Dokument bewerte ich die Matching-Vorschl"age des Herrn T\o{}ssebro, entwickele diese weiter und mache mir eigene Gedanken zu diesem Thema
\end{abstract}
\tableofcontents
\chapter{Ideen zu Matching}

\section{Die Vorschl"age von Erlend T\o{}ssebro}
In seinem Paper nannte der Autor drei verschiedene Matching-Strategien:
\begin{enumerate}
\item Position of centroid

Bestimme den Schwerpunkt jedes Cycles,  bilde aus diesen einen gewichteten Graphen, mit den Entfernungen als Kantengewichte und suche in Diesem "`N"achste Nachbarn"'.
\item Fixed threshold (set of cycles)

Matche zwei Cycles, wenn sie sich wechselseitig  mehr als threshold (in \%) "uberlappen.

\item Maximize Overlap (set of cycles)

Bilde einen gewichteten Graphen, in dem die Cycles Knoten sind, und dessen Kanten mit dem Grad der "Uberlappung gewichtet sind. Matche dann zwei Cycles, wenn sie wechselseitig zueinander die h"ochste "Uberlappung aufweisen.
\end{enumerate} 
\section{Meine Bewertung der Vorschl"age}
\begin{enumerate}
\item Position of centroid

In dem Paper wurde diese M"oglichkeit nicht weiter betrachtet, da er sagte, dass ein Referenzpunkt, der auch au"serhalb des Polygons liegen kann nicht gut sein kann. Hierzu muss ich anmerken, dass wir das Matching auf Ebene des ConvexHullTrees durchf"uhren, und das wir es hier nur mit konvexen H"ullen von Polygone zu tun haben. Der Schwerpunkt einer konvexen H"ulle liegt nat"urlich aber wieder innerhalb Dieser (wenngleich nicht zwangsl"aufig auch innerhalb des repr"asentierten Polygons). Au"serdem erscheint es plausibel, dass ein Referenzpunkt-Verfahren seine St"arke gerade dort haben wird, wo die "Uberlappungsalgorithmen ihre Schw"achen haben (bei sich schnell bewegenden, kleinen Objekten).

Der Vorschlag, zum machen "`N"achste Nachbarn"' zu benutzen, greift meiner Meinung nach zu kurz, es stellt sich n"amlich immer noch die Frage, wann man damit aufh"oren soll, nach den ersten 4 Paaren, oder sobald die Distanz "uber einen Schwellenwert kommt, oder wann? Diese Frage werde ich weiter unten behandeln.

\item Fixend threshold (set of cycles)

Zu diesem Verfahren kann ich eigentlich nicht viel sagen, ich habe es so implementiert, wie Erlend T\o{}ssebro das beschrieben hat, und es funktioniert.

\item Maximize Overlap (set of cycles)

Jeder Konten in diesem Graphen kann nur eine Kante mit h"ochstem Gewicht haben, also kann jeder Cycle auch nur mit einem einzigen Anderen gematcht werden. Dieses erscheint mir nicht sinnvoll, deshalb betrachte ich dieses Verfahren nicht weiter.

\item Matching mit dem Steiner-Punkt

In dem Aufsatz \cite{AAR} wurde das matching mit dem Steiner-Punkt als Referenzpunkt durchgef"uhrt. Auch wenn die Grundausrichtung dieser Arbeit von meiner verschieden ist, so ist es doch m"oglicherweise interessant, diese Spur weiterzuverfolgen. "Uber die Berechnung des Steiner-Punktes bin ich mir noch nicht im Klaren, gem"a"s dem Artikel wei"s ich aber, dass er in linearer Zeit zu berechnen ist. Zu dem eigentlichen Ablauf des Matchings gilt dasselbe, wie f"ur das Schwerpunktverfahren.
\end{enumerate}

\section{Matching mit Referenzpunkten}

Nehmen wir also an, wir haben eine M"oglichkeit, zu jedem Polygon, das wir matchen wollen einen Referenzpunkt zu berechnen. Dann k"onnen wir ein Feld aufbauen, in dem zu jeder Kombination von Cycles die Entfernung der Referenzpunkte eingetragen werden. Ordnen wir dieses Feld aufsteigend nach den Entfernungen, so steht zu erwarten, dass es zwischen den erw"unschten und den unerw"unschten Matches einen Sprung in dem Graphen geben wird. Diesen Sprung m"u"ste man mit geeigneten statistischen Verfahren finden k"onnen. Nachteilig an diesem Verfahren ist, dass die Laufzeit dieses Verfahrens hoch ist. Haben wir auf den beiden Seiten des Matchings $n$ beziehungsweise $m$ Referenzpunkte, so ist hat das resultierende Feld die Dimension $n\times m$. Dieses Feld kann man in $O(n\times m)$aufbauen. Zum Sortieren des Feldes braucht man dann $O((n\times m)\log(n\times m))$. Also ist dises Verfahren mindestens vom Typ $O((n\times m)\log(n\times m))$ (je nach dem verwendeten statistischen Verfahren k"onnte die laufzeit sogar schlechter sein).

\section{Die Wahl des Referenzpunktes}
In den Arbeiten \cite{AAR} und  \cite{AFRW} wurden der Schwerpunkt und der Steinerpunkt als m"ogliche Referenzpunkte gefunden. Ich fasse die Ergebnisse hier noch einmal zusammen:
http://www.gmx.net/de/
\subsection{\index{Hausdorff-Abstand}Der Hausdorff-Abstand}

Seien $A$ und $B$ zwei kompackte Teilmangen des $\mathbb{R}^2$ und sei $\Vert\centerdot\Vert$ die Euklidische Norm.
Dann definieren wir eine Hilfsfunktion $ \widetilde{\delta_H}  $, den einseitige Hausdoff-Abstand, wie folgt:
$$ \widetilde{\delta_H}(A,B):=\max_{a\in A} \;\min_{b\in B} \Vert a-b \Vert$$
Man kann sehen, dass der einseitige Hausdorf-Abstand von Polygon $A$ zu $B$ der Abstand des am weitesten entfernten Punktes aus $A$ zu dem im am n"achsten gelegenen Punkt aus $B$ ist. Dann ist der Hausdorff-Abstand $\delta_H$ definiert als:
$$\delta_H:=\max\{\widetilde{\delta_H}(A,B),\widetilde{\delta_H}(B,A)\}.$$


\subsection{Die symmetrische Differenz}

In \cite{AFRW} wird vorgeschlagen den Fl"acheninhalt der symmetrischen Differenz als Abstands-Ma"s zweier konvexer Polygone zu benutzen. Die Symmetrische Differenz von zwei kompakten Teilmengen $A$ und $B$ des $\mathbb{R}^2 $ ist definiert als:
$$A\bigtriangleup B:=(A\setminus B)\cup(B\setminus A).$$
Wenn $A(\cdot)$ der Fl"acheninhalt ist, so bildet $\delta_S$ den Abstand nach der symmetrischen Differenz:
$$\delta_S:=A(A \bigtriangleup B).$$

\subsection{Der Schwerpunkt}

Der Schwerpunkt eines Polygones ist der Schwerpunkt der Massenverteilung, die entsteht, wenn man allen Eckpunkten die selbe Masse zuordnet. Er berechnet sich f"ur ein Polygon $P$ mit $n$ Eckpunkten $v_i$:
$$p_0(P)=\sum^n_{i=1}v_i \frac{1}{n}.$$

\subsection{Der Steiner-Punkt}

In \cite{Sch} wird der Steinerpunkt beschrieben: "`als Schwerpunkt der Massenverteilung, die bei einem konvexen Polygon duch Belegung der Ecken mit den "au"seren Winkeln als Massen [...] gegeben ist"'. Also kann man den Steiner-Punkt eines konvexen Polygones $P$, das aus den $n$ Eckpunkten $v_i$ besteht, berechen ($\alpha_i$ ist hierbei der Innenwinkel von $v_i$):
$$p_2(P)=\sum^n_{i=1}v_i (\pi-\alpha_i).$$

\section{Mehrere Matchings besser als eines}

Wenn man die bereits ausprobierten Matchings betrachtet, so stellt man fest, dass das Overlapping-Match besser auf Vereinigungen und Aufsplitterungen von Cycles reagiert, und dass das Schwerpunkt-Verfahren besser auf kleine und schnelle Cycles abgestimmt ist. 

Es scheint also ein verfolgenswerter Ansatz zu sein, beide Matches (und vielleicht noch andere, etwa Overlapping mit mehreren Schwellwerten), zu berechnen, und aus diesen das beste Matching zu bestimmen. Um die G"ute eines gegebenen Matchings zu bestimmen, habe ich folgende Verfahren erdacht:
\begin{itemize}
\item Die Overlapp-Bewertung: 

Ist der Duchschnitt der "Uberlappungen gro"s, so ist das gut.

\item Die Schwerpunkt-Bewertung:

Ist die durchschnittliche Entfernung der zueinander gematchten Schwerpunkte gro"s, so ist das schlecht.

\item Die Summen Norm:

Sind die zueinander gematchten Fl"achen etwa gleich gro"s, so ist das gut.

\item Die Struktur-Norm:

Stimmen die aufeinander gematchten Cycles strukturell weit "uberein, so ist das gut (eventuell kann man hier die Struktur der jeweiligen ConvexHullTrees heranziehen).

\end{itemize} 

Wie man am Beispiel der Summen-Norm sehen kann, gibt es mehr M"oglichkeiten zu bewerten, als es effiziente Matchings gibt. Das Summen-Matching, das lauten k"onnte: "`Matche ein Cycle mit  einer Menge von Anderen, wenn die Summe der Fl"acheninhalte fast gleich ist zu dem Fl"acheninhalt des einen Cycles"', entspricht dem Rucksack-Problem und ist daher nicht effizient l"osbar. Die Bewertung, wie gut ein gegebenes Matching ist, sollte mit diesem Verfahren aber effizient m"oglich sein.
\printindex
\bibliography{literatur}

\bibliographystyle{geralpha}
\end{document}
