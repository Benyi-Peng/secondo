\documentclass[a4paper]{article}
%\usepackage[left=3cm, right=3cm]{geometry}
\usepackage[utf8x]{inputenc}
\usepackage{float}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{url}
\usepackage{array}
\usepackage{algorithmic}
\usepackage[ruled]{algorithm}
\usepackage{color}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{todonotes}
\usepackage{rotating}
\pagestyle{headings}
\newcommand{\secondo}{\textsc{Secondo}}
\newcommand{\bmodb} {BerlinMOD Benchmark}
\newcommand{\op}[1]{\textbf{#1}}
\newcommand{\dt}[1]{\textsl{\underline{#1}}}
\newcommand{\true}{\textsl{TRUE}}
\newcommand{\false}{\textsl{FALSE}}
%opening
\title{Network Data Model and BerlinMOD Benchmark}
\author{Simone Jandt}
\date{Last Update: \today}
\begin{document}
\maketitle
\begin{abstract}
In the past, several data models for the representation of histories of
spatio-temporal data objects have been developed. We can categorize these data
models
into data models for objects moving freely in the two dimensional space and data
models for network constrained moving objects. In this paper we select two
representatives,
one for each data model category, which are both implemented in the \secondo{} DBMS,
and compare their capabilities with the \bmodb{}. We describe our implementation
of the used network constrained data model, the translation
from the \bmodb{} into the network constrained data model, and show
that in our experiments the network constrained data model outperforms the data
model of free movement in the two dimensional space by orders of magnitude.
\end{abstract}
\listoftodos
\section{Introduction}
In the past, several data models for the representation of
spatio-temporal data objects have been developed. We can categorize them into
data models for objects moving freely in two dimensional space (DMFS) and data
models
for network constrained moving objects (NCDM). For both categories several different
data models have been presented like
\cite{DataModelDataStructureGueting,RepresentingMovingObjectsGueting,STAUPelekis
,HERMESMDCPelekis}
for DMFS and
\cite{DynamicTransportNetworkDing,NetworkGueting,NetworkJensen,
NetworkVazirgiannis}
for NCDM, to name just a few. Objects which are restricted to use existing networks,
like cars are restricted to use road networks, can be represented as moving point
objects in both data models, whereas objects, which are not restricted by a given
network, like people, can be represented as moving point objects only in DMFS.

Why do we spend time on NCDM, if everything can be represented by DMFS?
Now, it is natural to give positions related to the street
network instead of x,y-coordinates. NCDM are expected to use less storage space,
because geographical information's about street curves are stored only once in
the network, whereas in DMFS each street curve is stored in each moving point
object using this street. NCDM can support query processing with specialized indexes
using their knowledge of the underlying network. It is much easier to
formulate queries about the relationships between moving objects and the network
in the NCDM. And not at last, the results of our experiments show that
our network constrained data model outperforms our data model of free movement in
two dimensional space by orders of magnitude. The network constrained data model
uses less than 60\% of the storage space and less than 50\% of the total query
run time of the data model of free movement in space, which we used in our
experiments.
We think that these results show that it is useful to develop specialized data
models for specialized data structures like NCDM for
network constrained moving objects to save storage space and reduce query run times.

For our benchmark experiments, presented in this paper, we chose two data models
one for each data model category. Both data models use the same temporal
representation
and are available in \secondo{} DBMS
\cite{SecondoEnvironmentDieker,SecondoPlatformPrototypingGueting}.
So we can exclude that different DBMS or temporal representation issues bias the
results of our data model comparison with the \bmodb{}\cite{BerlinMODVLDBDuentgen}.
The DMFS we use is the data model presented in
\cite{RepresentingMovingObjectsGueting,DataModelDataStructureGueting}
(SPACE). And the NCDM we use is the data model presented in
\cite{NetworkGueting} (NET).

We used the \bmodb{} \cite{BerlinMODVLDBDuentgen} to compare the capabilities of
the two data models, because the \bmodb{} is to the best of our knowledge the
first benchmark for complete spatio-temporal database systems.
It is developed and available in \secondo{} DBMS. And the data generated by the
\bmodb{} data generator are restricted to the streets of the German capital Berlin,
such that they can be translated into a network constrained environment.
And not at last, the data model used in the \bmodb{} is SPACE that we use
for our comparison. So we only have to translate the spatial and spatio-temporal
data types of the \bmodb{} once into our NET representation. This simplifies the
control of the query results and avoids errors caused by translation.
The translation of the spatial and spatio-temporal data types of the \bmodb{} data
into the NET representation described in Section \ref{sec:Translation} can be
seen as an example for the usage of the \bmodb{} with other compatible data
representations or DBMS.

Besides the comparsion of the both data models, we describe in this paper the
first real implementation of NET (see Section \ref{sec:implNDM}) providing some
further concepts which were only sketched in \cite{NetworkGueting}.

The rest of the paper is organised as follows: We present some related work in
Section
\ref{sec:relWork}, including short reviews of the underlying \secondo{} DBMS
(Section \ref{sec:secondo}), the two data models (SPACE Section
\ref{sec:bmodbdatamod},
NET Section \ref{sec:netdatamod}) we chose for our comparison, and the
\bmodb{} (Section \ref{sec:bmodb}).
In Section \ref{sec:implNDM} we give some information's about our implementation
of NET, the used operations and indexes.
The translation of the \bmodb{} data and query set into the NET representation
is described in Section \ref{sec:Translation}. The resulting experimental benchmark
setup is described in Section \ref{sec:scenario} followed by the results of our
experiments in Section \ref{sec:results}. We conclude our work in Section
\ref{sec:summary}.
\section{Related Work}
\label{sec:relWork}
In the past many different spatio-temporal data models have been presented. Many
of them support only discrete spatio-temporal changes like
\cite{sqlstchen,HunterWilliamson,Langran2,Langran1,Ramadrachan}
or deal only with current and future positions of continuously moving objects like
\cite{MOSTWolfson}. More detailed reviews of these and other spatio-temporal
data models beyond the scope of our paper can be found in \cite{ReviewSTDMPelekis}.

In this paper we will focus on spatio-temporal data models for complete histories
of continuously moving objects. These can be categorized into data models for
objects moving freely in two dimensional space (DMFS) and data models for network
constrained moving objects (NCDM).

\cite{MOLRaQSu} proposes an incomplete abstract DMFS. Basic idea is that
spatio-temporal data types can be modeled by linear constraints and queries are
formulated using formulas from differential geometry.

\cite{RepresentingMovingObjectsGueting} proposes an abstract DMFS including the
idea of an time sliced representation for moving objects. This basic idea of
time sliced representation is used by the DMFS \cite{STAUPelekis} and
\cite{DataModelDataStructureGueting}. The last one is used in our experiments
and therefore reviewed in more detail in Section \ref{sec:bmodbdatamod}.
The main difference between the both data models is that
\cite{DataModelDataStructureGueting} supports only linear interpolation of movement,
whereas \cite{STAUPelekis} also supports arc interpolation of movement.
\cite{STAUPelekis} uses only one spatial object
containing all spatial geometries for the representation of spatial objects and
one moving object for the representation of the different moving object data types,
whereas \cite{DataModelDataStructureGueting} uses different spatial and moving
objects for the representation of the different spatial and moving data types.
According to this \cite{STAUPelekis} provides only a single operator that
distinguishes
between the different topological relationships via a parameter, whereas
\cite{DataModelDataStructureGueting} uses different operations to estimate
topological relationships. Overall, \cite{STAUPelekis} offers a more flexible
object oriented design than \cite{DataModelDataStructureGueting}.

The spatio-temporal framework of \cite{RepresentingMovingObjectsGueting} used by
\cite{DataModelDataStructureGueting} has been used for the definition of a
NCDM in \cite{NetworkGueting}.

The most NCDM use edge based graph representations for the representation of the
underlying network data only a small number of NCDM uses route oriented data models
or combine route and edge based data models.

\cite{NetworkVazirgiannis} proposes an edge based NCDM. The edges and their
attributes
are stored in a relation representing the network as an undirected graph. Moving
objects are assumed to drive always on the path with the lowest cost,
in terms of distance or travel-time. They are defined by the source point, the
target point, and the starting time instant of the trip. The trajectory is
computed by this assumption using the length and speed attributes of the graph
edges within the shortest respectively fastest path computation.
The advantage of this definition is the reduced storage space for the representation
of moving point objects. The drawback is the high computational effort for query
evaluation on moving objects.

\cite{NetworkJensen} uses also an edge based network representation. The paper
proposes a combination of an two dimensional geometrical edge representation with
an directed graph representation of the same network. The both representations
are connected by transition policies. The two dimensional
geometrical representation handles the spatial information's, whereas the
connectivity
information is mostly embedded in the directed graph representation.
Moving objects are represented by sets of five tuples. Each five tuple contains
an edge identifier, the position of the moving point on the edge
in terms of weight and length, the speed and direction of the movement, and
the time instant of this information.

Another two-layer network representation is proposed by
\cite{DynamicTransportNetworkDing}.
The authors of \cite{DynamicTransportNetworkDing} combine the advantages of the
dynamic edge-based \cite{DynNetworkModEdgeGueting} and the dynamic route-based
\cite{DynNetworkModRouteGueting} NCDM approaches. The route-based environment
reduces the update intervals and used storage space for the database representation
of moving point objects, whereas the edge-based environment supports
a more detailed view on the traffic conditions of the different edges belonging
to the same route. Moving objects are represented by a set of pairs. The pairs
consist of an motion vector and an Boolean flag. The Boolean flag tells if the
motion vector contains current or historical information. Each motion vector
consists, in parts similar to \cite{NetworkJensen}, of a time stamp, a network
position, and a speed vector. Similar to \cite{NetworkGueting} the network
position bases on routes and junctions and not on edges. Different from all
other NCDM in this section \cite{DynamicTransportNetworkDing}
uses time depending dynamic attributes in the representation of the network parts.
Therefore, changes in the network environment can be handled without loss of
information in this NCDM.

To the best of our knowledge only a few of the proposed data models have been
implemented into database management systems: \cite{STAUPelekis} is implemented
as data cartridge \cite{HERMESMDCPelekis, HERMESPelekis} for the commercial
Oracle\textregistered object-relational DBMS \cite{oracle};
\cite{DynamicTransportNetworkDing} is implemented as extension of the open source
database project PostgreSQL \cite{PostgreSQL}; \cite{DataModelDataStructureGueting}
and \cite{NetworkGueting} are implemented in the freely available extensible
\secondo{} DBMS \cite{SecondoPlatformPrototypingGueting}.

Although \cite{STAUPelekis} for the DMFS and \cite{DynamicTransportNetworkDing} for
the NCDM provide greater flexibility we decided to use
\cite{DataModelDataStructureGueting} and \cite{NetworkGueting} in our
experiments, because both data models are available in the same DBMS, which is
also the DBMS in which the \bmodb{} \cite{BerlinMODVLDBDuentgen} has bee developed.

The \bmodb{} \cite{BerlinMODVLDBDuentgen} is to the best of our knowledge the only
benchmark testing the capabilities of complete spatio-temporal database systems.
Coming with a well defined data set, and two query sets feasible for DMFS and NCDM.
Other benchmarks for spatio-temporal databases systems provide only well defined
query sets and a database description without any data set like
\cite{QueriesTheodoridis}.
Or they come with well defined data generation, workload sets and experiments but
evaluate only the capabilties of indexes for current and near future positions like
\cite{COSTBenchmarkJensen}. Or they focus on time-evolving regional data and
associated
index methods like \cite{BenchmarkTzouramanis}.

The focus on index benchmarking in the most benchmarks is dued by the fact that
indexes have a great influence on query run times. Therefore, many spatio-temporal
indexes have been developed in the last ten years. An survey about existing
spatio-temporal
indexes can be found in the two parted work \cite{STAMSurvey1} and
\cite{STAMSurvey2}.
The most presented spatio-temporal indexes base on the R-Tree \cite{RTreeGuttmann}
and its variants. The R-Trees are used stand alone or in hierarchical combinations.
B-Trees \cite{BTreeBayer} and their variants are also used within spatio-temporal
indexes. \secondo{} comes with implementations of R-Tree, B-Tree, and MON-Tree
\cite{MONTreeAlmeidaGeoinformatica} in Section \ref{sec:implNDM} we give a detailed
description how we used these indexes in our experiments.

The \bmodb{} comes with his own data generator. Like mentioned before other
benchmarks like \cite{QueriesTheodoridis} define only database descriptions.
The users have to generate their own corresponding data.

Therefore, several data generators have been developed. Some of them generate
only unconstrained moving point objects like \cite{OportoSaglio}, or support
only short-term observations like \cite{BrinkhoffsDataGenerator}, or are
unavailable respectively require additional software like \cite{STACTS}.

In the sequel we give short reviews of the \secondo{} DBMS
(Section \ref{sec:secondo}), the both data models we used in our experiments
(Section \ref{sec:bmodbdatamod} and Section \ref{sec:netdatamod}), and the \bmodb{}
(Section \ref{sec:bmodb}).
\subsection{\secondo{} DBMS}
\label{sec:secondo}
The extensible \secondo{} DBMS presented in
\cite{SecondoEnvironmentDieker,SecondoPlatformPrototypingGueting} provides a
platform for implementing various kinds of data models. It provides a clean
interface between the data model independent system frame and the content of the
single data models. Hence \secondo{} can be easily extended by the user
implementing algebra modules to introduce new data types and operations on
these data types. The user may define additional viewers for the graphical user
interface or write additional optimization rules or cost functions to extend the
the optimizer. Since \secondo{} version 2.9 the users may publish their extensions
as a \secondo{} plugin such that other users can use these plugins to extend
their own
\secondo{} system. They may use the newly provided functionalities or repeat the
published experiments. \secondo{} is freely available on the web \cite{secondoweb}.
It comes with a number of already implemented spatial and spatio-temporal data types
and operations including SPACE (Section \ref{sec:bmodbdatamod}) and NET
(Section \ref{sec:netdatamod}). Furthermore, the \bmodb{}
described in Section \ref{sec:bmodb} has been developed in the \secondo{} DBMS.
For our experiments we used the \secondo{} version 3.0.
\subsection{Data Model of \bmodb{} (SPACE)}
\label{sec:bmodbdatamod}
\cite{STDTModelingQueryingMOinDErwig} presents the basic idea of the DMFS that
is used by the \bmodb{}. The abstract data model for SPACE was pubished in
\cite{RepresentingMovingObjectsGueting} and the discrete data model in
\cite{DataModelDataStructureGueting}. Abstract data models are useful as conceptual
models, but they cannot be implemented, because computers can only use finite sets.
In the sequel description we will mainly focus on the discrete data model.

The type system in \cite{RepresentingMovingObjectsGueting} is defined using the
techniques presented in \cite{SecondOrderSignatureGueting}. The basic idea of
\cite{RepresentingMovingObjectsGueting} is to define type constructors
that create new data types if they are applied to an data type of a given set of
basic data types.

Basic data types are the standard data types integer, real, string and boolean
(BASE);
the spatial data types point, points, line, and region (SPATIAL);
and the temporal type instant (TIME).

The carrier sets for all data types in the discrete data model contain $\perp$,
representing an undefined value. This is not mentioned any more in the sequel.

The carrier sets for the BASE data types in the discrete data model are defined
by the corresponding programming language data types \dt{int}, \dt{real}, \dt{bool},
and \dt{string}. The carrier set of a value of the data type \dt{point} is
\dt{real} $\times$ \dt{real}. The two \dt{real} values represent the x,y-coordinates
of the \dt{point} value in the two dimensional plane. The data type \dt{points}
consists of a disjoint set of \dt{point} values. The carrier set for the data
type \dt{line}
consists of a finite set of disjoint line segments representing the linear
approximation of the line curve in the two dimensional plane. Semanticaly an
\dt{line} value is the union of the points of all its line segments. A region
is the union of all points covered by the region. The carrier set \dt{region}
is defined to be a finite set of line segments building a polygon representing
the linear approximation of the outer and, if the region contains wholes, inner
borders of the region. The borders are defined to belong to the region.

The carrier set for the TIME data type is given by \dt{real} in the discrete
data model.
That means each time \dt{instant} is represented by a corresponding \dt{real}
value.

The type constructor \dt{range} converts BASE and TIME data types $\alpha$ into
a type whoes values are finite sets of intervals over $\alpha$. Range types are
used to represent collections of time intervals, or the values taken by a moving
real. Intervals are represented by their start and end point and two flags
indicating
if the start respectively end point is part of the interval or not.

The other important type constructor of the abstract data model is \dt{moving}.
In the abstract data model\dt{moving} maps each data type $\alpha$ from BASE and
SPATIAL into an time dependend spatio-temporal moving data type
\dt{moving}($\alpha$)
(\dt{m$\alpha$} for short) of kind TEMPORAL. The discrete data model introduces some
additional type constructors to implement the moving type constructor of the
abstract data model. A detailed description of the type constructors is skiped
due to place limitations. We explain the realisation of \dt{moving} at the example
of a \dt{moving}(\dt{point}) (short \dt{mpoint}) object. An \dt{mpoint} value
may represent a car, which changes its position in the plain within time.

An \dt{mpoint} consists of a set of so called \dt{unit}(\dt{point}) values
(\dt{upoint} for short).
Each \dt{upoint} consists of a time interval and two \dt{point} values. The first
\dt{point} value represents the position of the \dt{upoint} at the start of the
time interval and the second \dt{point} value represents the position of the
\dt{upoint} at the end of the time interval. It is assumed that the object
represented
by the \dt{upoint} moves on the straight line between these two points with constant
speed within the given time interval. The velocity of the object is given by the
ratio from the distance of the two points and the length of the time interval of
the \dt{upoint}.

All \dt{upoint} values of an \dt{mpoint} must have disjoint time intervals,
because a car cannot be at two different positions at the same time.
The set of \dt{upoint} values is sorted by ascending time intervals.

This spatio-temporal data model of \dt{moving} allows us to compute the position
of an \dt{mpoint} at every time instant within its definition time.
We can also compute the time instant the point passed a
given position assuming the \dt{mpoint} ever passes this position. The position of a
\dt{point} at a given time instant is represented by an \dt{intime(point)}
(short form \dt{ipoint}). An \dt{ipoint} consists of an time instant and an
\dt{point}
value and represents the position of the \dt{mpoint} value at the given time
instant.

Other data types of \secondo{} which are used in the \bmodb{} are \dt{mbool},
\dt{mreal}, and \dt{periods}. A \dt{mbool} value consists of a set of \dt{ubool}
values. Each \dt{ubool} value is is constant \true{} or \false{} for the given
time interval. A \dt{mreal} value consists of a set of \dt{ureal} values. Each
\dt{ureal} value is defined by a function of time representing the \dt{real}
value at each time instant. A \dt{periods} value is a set of disjoint an not
connected time intervals.
\subsection{Network Data Model(NET)}
\label{sec:netdatamod}
The central idea of the NDM presented in \cite{NetworkGueting} is that
every movement is constrained by a given network and every position can be described
relative to this network. Contrary to the most other NCDM NET models the network
in terms of routes, corresponding to roads or highways in real life. Positions
are given by a route identifier and the distance from the start of the route.
This is a more natural representation of network positions as the directed graph
representation of networks, where junctions are vertexes and the pieces between
junctions are represented by edges, which is used in the most NCDM. We have names
for roads not for junctions or pieces between junctions.

The routes based network representation has also the advantage that the
representation of moving objects that move over several sections of the same route
with constant speed becomes much smaller, because we only have to store new
information if the moving object changes the road or the speed. Not every time
it passes a junction like in the other NCDM.

In NET the data type \dt{network} is modeled by two main components. One is the
set  of routes (streets) and the other one the set of junctions (crossings). The
domain of routes is defined as
\[
\begin{split}
Route = \{(id,\ l,\ c,\ kind,\ start)\ &|\ id \in \dt{int},\ l \in \dt{real},
\ c \in \dt{line},\\
&\ kind \in \{simple,\ dual\},\\
&\ start \in \{smaller,\ larger\}\},
\end{split}
\]
where $id$ is a distinct route idenitfier, $l$ is the length of the route, $c$
is the route curve as \dt{line} value (see Section \ref{sec:bmodbdatamod}),
$kind$ indicates if the lanes of the route are separated, and $start$ indicates
how the route curve is embedded into space.

If $R$ is a set of distinct routes, the domain of junctions in $R$ is defined as
\[
  \begin{split}
    Junction(R)=\{(rm_1,\ rm_2,\ cc)\ &|\ rm_1,\ rm_2 \in RMeas(R),\\
&rm_1 = (r_1,\ d_1),\ rm_2 = (r_2, d_2),\\
&r_1 \neq r_2, cc \in \dt{int}\}.
  \end{split}
\]
Where the set of possible positions in $R\ RMeas(R)$ is defined as
\[
  \begin{split}
    RMeas(R) = \{(rid, d)\ &|\ rid \in \dt{int},\ d \in \dt{real},\\
&\exists (rid,\ l,\ c,\ k,\ s) \in R \wedge 0 \leq d \leq l\},
  \end{split}
\]
and $d$ is the distance from the start of the route.
The connectivity code $cc$ encodes which lanes of the roads are connected
by the junction\footnote{See \cite{NetworkGueting} for detailed explanations.}.

A network $N$ is a pair $(R,\ J)$, where $R$ is a finite set of distinct routes
and $J$ is a finite set of junctions in $R$. The carrier set for network
positions $Loc(N)$ is equal to the set of route locations and defined as
\[
  \begin{split}
    RLoc(R)=\{(rid,\ d,\ side)\ &|\ (rid,\ d) \in RMeas(R),\\
&side \in \{up,\ down,\ none\}\}.
  \end{split}
\]
The $side$ value indicates for $dual$ routes if a position can be reached
from the $up$ or the $down$ side of the route. For routes with $kind = simple$ the
$side$ value is always $none$.

Let $N=\{N_1,\ldots,N_k\}$ be a set of networks. A single network position in a
network $N_i$ is represented by the data type \dt{gpoint}. The carrier set of
\dt{gpoint} is defined as
\[\{(i,\ gp)\ |\ 1 \leq i \leq k \wedge gp \in RLoc(R) \cup \{ \perp \}\},\]
where $\perp$ again represents a undefined value.

A $route\ interval$ in $N_i$ is a pair of network positions on the same route. The $route\ interval$ is represented by a quadruple $(rid,\ d_1,\ d_2,\ side)$, with
$(rid,\ d_1,\ side),\ (rid,\ d_2,\ side) \in Loc(N)$
and $d_1 \leq d_2$. Semantically
a $route interval$ represents all route locations $(rid,\ d,\ side)$ with
$d_1 \leq d \leq d_2$. A finite set of disjoint $route\ intervals$ of a network
$N$ is called region of $N$. The set of all possible regions in a network $N$ is
denoted as $Reg(N)$.

A region within an network $N_i$ is represented by the data type \dt{gline}.
The carrier set of \dt{gline} is defined as
\[\{(i,\ gl)\ |\ 1 \leq i \leq k \wedge gl \in Reg(N_i) \}\].
The set of $route intervals$ defining a network region may be empty.

The type systesm of \cite{RepresentingMovingObjectsGueting} is extended by
\cite{NetworkGueting} to contain a new kind GRAPH consisting of the data types
\dt{gpoint} and \dt{gline}. The type constructors \dt{moving} is also extended
to be feasible for data types of kind GRAPH. Therefore the data type
\dt{moving}(\dt{gpoint}) (\dt{mgpoint} for short) is defined similar to the
\dt{mpoint} explained in detail in Section \ref{sec:bmodbdatamod}. The units of
a \dt{mgpoint} consist of \dt{ugpoint} values and single positions can be given
by \dt{igpoint} values.

The paper provides numerous operations on the network and the network data types.
We give reviews of the operations that were used in our experiments later in this
paper (see sections \ref{sec:implNDM} - \ref{sec:Translation}).

\cite{NetworkGueting} proposes also implementational issues for NET in
\secondo{}. The implementation of the data type \dt{network} consists of three
relations called $routes$, $junctions$, and $sections$, and a persistent adjacency
list data structure supporting trip and path computations.

The three relations have the following schemas:
\begin{ttfamily}
\begin{itemize}
  \item [] routes (id:int; length: real; curve: line; kind: bool;\\
 start: bool)
  \item [] junctions (r1id: int; r1rc: int; pos1: real; r2id: int;\\
r2rc: int; pos2: real; cc: int; pos: point)
  \item [] sections (rid: int; rrc: int; pos1: real; pos2: real;\\
dual: bool; length: real; curve: line)
\end{itemize}
\end{ttfamily}
As you can see, the $routes$ relation is equivalent to the domain of routes $Route$.
The tuple of the $junctions$ relation is somewhat different from $Junctions(R)$.
The record identifiers $r1rc$ and $r2rc$ support faster access to the corresponding
tuples in the $routes$ relation and the \dt{point} value $pos$ supports the
connection
to the two dimensional plane.

The $sections$ relation is derived from the other two relations. The meaning of
the $rrc$ value is similar to the meaning of $r1rc$ in the $junctions$ relation.
The entries of the $sections$ relation correspond to the edges of a network graph.
They are used internally to support operations like \op{shortestpath}. The adjacency
list data structure consists of two arrays and provides a fast
access from each section to their adjacent sections with respect to the driving
direction. Two sections are adjacent if their lanes are connected by a junction.

For the data types \dt{gpoint} and \dt{gline} \cite{NetworkGueting} proposes
the following implementations:
\begin{ttfamily}
\begin{itemize}
  \item [] gpoint: record \{nid: int; rid: int; pos: real;\\
side: \{up, down, none\};\}
  \item [] gline: record\{nid: int; rints: DBArray of record \{\\
rid: int; pos1: real; pos2: real;\\
side: \{up, down, none\};\}
\end{itemize}
\end{ttfamily}
For the data type \dt{mgpoint} the implementation consists of a set of \dt{ugpoint}.
The set is stored in a DBArray in ascending order of the time intervals of the
\dt{ugpoint}. Each \dt{ugpoint} is defined as:
\begin{ttfamily}
\begin{itemize}
  \item [] ugpoint: record \{nid: int; rid: int; pos1: real;\\
pos2: real; side: \{up, down, none\};\\
t1: Instant; t2: Instant;\}
\end{itemize}
\end{ttfamily}
The \dt{ugpoint} is expected to move from $pos_1$ to $pos_2$ with constant speed on
route $rid$ in the given network $nid$ within the time interval defined by $t_1$
and $t_2$. Every time a \dt{mgpoint} changes the speed or changes the route a new
\dt{ugpoint} is written.

We extended this implementation proposed by \cite{NetworkGueting} within our
experiments to support faster query execution. Our changes will be described in
detail in Section \ref{sec:implNDM}.
\subsection{BerlinMOD Benchmark}
\label{sec:bmodb}
The \bmodb{} was presented in \cite{BerlinMODVLDBDuentgen} and the
provided scripts for the data generator are implemented as \secondo{} DBMS
operations.
The \bmodb{} is available on the web \cite{berlinmodweb} and provides a well defined
data-set and queries for the experimental evaluation of the capabilities of
spatial and spatio-temporal database systems dealing with histories of moving
objects. The \bmodb{} emphasises the development of complete systems
and simplifies experimental repeatability pointing out the capabilities and the
weaknesses of the benchmarked systems.

The data-sets of the \bmodb{} are created using the street map of the German
capital Berlin \cite{bbike} and statistical data about the regions of Berlin
\cite{bevberlin,berlinstadtatlas} as input relations.
The created moving objects represent cars driving in the streets of Berlin,
simulating the behaviour of people living and working in Berlin.
Every moving object has a home node and a work node. Every weekday each car will
do a trip from the home node to the work node in the morning and vice versa
in the late afternoon. Beside this, randomly chosen cars will make additional
trips in the evening and up to six times at the weekend to randomly chosen
targets in Berlin and back home. The \bmodb{} uses the data model of free
movement in two dimensional space described in Section \ref{sec:bmodbdatamod}.
Because the \bmodb{} generates all data sets restricted to the street map of
Berlin, the \bmodb{} can also be used for network constrained data models, if
the spatial and spatio-temporal data types are translated into a corresponding
NDM, like we did for our experiments.

The number of observed cars and the duration of the observation period can be
influenced by the user setting the $scalefactor$ to different values in the data
generation script of the \bmodb{}. For example at $scalefactor$ 1.0 the data
generator creates 2000 moving point objects observed for 28 days, each of them
sending a GPS-signal every 2 seconds. These simulated signals are simplified
such that time intervals when a car does not move or moves in the same direction
at the same speed are merged into one single time interval. For example: If a
car is parked in front of the work node for 8 hours, there will be only one
entry in the history of the cars movement with a time interval of 8 hours
instead of 14.400 entries, one for each GPS time interval.

The \bmodb{} provides two different approaches to store the histories of moving
objects, called the object-based approach (OBA) and the trip based approach (TBA),
respectively.

In the OBA, the complete history for each moving object is kept together in one
single entry. There is only one relation $dataScar$
containing one tuple for each object consisting of the spatio-temporal data of
the object $journey$, the $licence$, the $type$, and the $model$ of the object.

In the TBA, we have two relations $dataMcar$ and $dataMtrip$. $dataMcar$ contains
the static data for each object like $licence$, $type$, and $model$ together with
an object identifier $moid$. $dataMtrip$ contains for each $moid$ several tuples,
each of them containing either all units of a single trip of the moving object, or a
single unit for a longer stop. For example, each time the car drives from home node
to work node is a single trip, and each time the car is parked in front of the
office is also a single trip.

Besides the moving point objects, the \bmodb{} provides several data sets, each
of them containing 100 pseudo randomly generated data objects, which are used in
the benchmark queries. Table \ref{tab:queryobjects} gives an overview of these
query objects. The \bmodb{} deals also with subsets from these query object
sets consisting of the first or second 10 query objects of a query object set.
They are labeled by the name of the query object set followed by a 1 for the
first ten or a 2 for the second ten query objects.

\begin{table}[H]
  \begin{tabularx}{1.0\textwidth}{|l|X|}
    \hline
    \textbf{Name of Data Set}&\textbf{Tuple Content}\\
    \hline
    $QueryPoints$&Object identifier and \dt{point} value\\
    \hline
    $QueryRegions$&Object identifier and \dt{region} value\\
    \hline
    $QueryInstants$&Object identifier and time instant\\
    \hline
    $QueryPeriods$&Object identifier and time interval\\
    \hline
    $QueryLicences$& Object identifier and a \dt{string} representing a licence value\\
    \hline
  \end{tabularx}
  \caption{Query Object Relations of \bmodb{}}
  \label{tab:queryobjects}
\end{table}

The \bmodb{} provides two sets of queries BerlinMOD/R and BerlinMOD/NN.
BerlinMOD/R addresses range queries and BerlinMOD/NN nearest neighbour queries.
In this paper we will focus on the range queries, which are the main aspect of the
\bmodb{} up to now.

The query set BerlinMOD/R includes 17 queries selected of the set of possible
combinations of the 5 aspects:
\begin{itemize}
  \item known or unknown object identity,
  \item standard attribute, spatial, temporal, or spatio-temporal dimension,
  \item point, range, or unbounded query interval,
  \item single object or object relationships condition type,
  \item with or without aggregation.
\end{itemize}
We will present the 17 queries in more detail in Section
\ref{sec:queries}\todo[caption={check reference}]{Check reference when paper
finished. Parts of query explanations might be moved to the appendix.}
together with our NDM algorithms for these queries.
\section{Implementation of NET}
\label{sec:implNDM}
We started a description of the implementation of NET in \secondo{} in Section
\ref{sec:netdatamod} with the description of the implementation proposed in
\cite{NetworkGueting}. In the meantime this implementation has been changed and
extended in some points to support faster query execution.

In the sequel we describe the current implementation of the NET data types in
Section \ref{sec:implNetDataTyp}, new data types for network position indexes
are presented in Section \ref{sec:implNetIndex}, and the implementation of
operations used by the \bmodb{} in Section \ref{sec:implNetOperations}.

\subsection{Data Type Implementation}
\label{sec:implNetDataTyp}
First of all the \dt{network} object itself has been changed. The $junctions$
relation has been extended by four additional record identifiers, one for each
section connected within this junction. Four B-Tree indexes for the route
identifier attributes in the $routes$, $junctions$, and $sections$ relations
haven been integrated. An R-Tree has been integrated indexing the curve attribute
of the $routes$ relation. All this has been done to support faster access to
spatial routes data in query evaluation.

The $side$ value of the $route\ intervals$ is not yet part of the implementation.

\label{sec:sortedgline}
The record of \dt{gline} was extended by an attribute $length$ of
\dt{real}, storing the length of the \dt{gline}, and an sorted flag, indicating
if the $route\ intervals$ in the DBArray are stored sorted or not. We call a
set of $route\ intervals$ sorted if it fullfills the following conditions:
\begin{itemize}
   \item all $route\ intervals$ are disjoint
   \item the $route\ intervals$ are stored in ascending order of their route identifiers
   \item if two $route\ intervals$ have the same route identifier, the
$route\ interval$ with the smaller start position is stored first if the
$route\ intervals$ are disjoint
   \item for all $route\ intervals$, $start\ position \le end\ position$
\end{itemize}
We introduced this definition and sorted flag, because many algorithms take profit
from sorted \dt{gline} values. Let $r$ be the number of $route\ intervals$ in a
\dt{gline}, the decision, if a \dt{gpoint} is inside the \dt{gline} needs O($r$)
time for unsorted and O($\log r$) time for sorted \dt{gline} values.

Unfortunately not all \dt{gline} values can be stored sorted. If a \dt{gline}
value represents a path between two \dt{gpoint} in the network, we need the
route intervals exactly in the sequence they are used in the path. This will
nearly never be a sorted set like defined before.  We store \dt{gline}
values sorted whenever this is possible to support faster query execution.
Every algorithm which deals with \dt{gline} values checks this flag and uses
the corresponding code.

For sorting and compressing $route\ intervals$ we introduced a binary tree
data structure called $RITree$. This $RITree$ sorts and compresses the inserted
$route\ intervals$. If $r_i$ is the number of inserted $route\ intervals$ and
$r_{res}$ the number of resulting $route\ intervals$ sorting and compressing takes
O($r_i \log r_{res}$) time. The sorted $route\ intervals$ are returned in
O($r_{res}$) time. We think that this time is well invested, because the sorted
\dt{gline} is computed once, but many different algorithms can be executed faster
for sorted \dt{gline} values.

The implementation of the \dt{ugpoint} has been changed to:
\begin{ttfamily}
\begin{itemize}
  \item [] ugpoint: record \{gp1: gpoint; gp2: gpoint;\\
ti : Interval;\}
\end{itemize}
\end{ttfamily}
Where $t_i$ is a time interval consisting of two time instants $t_1$ and $t_2$
and
two Boolean flags, indicating if $t_1$ respectively $t_2$ is part of the time
interval
or not.

At the same time the implementation of \dt{mgpoint} has been extended to:
\begin{ttfamily}
\begin{itemize}
  \item [] mgpoint: record \{units: DBArray of ugpoint;\\
drivenDist: real; trajDefined: bool; mbr: rectangle3D\\
trajectory: DBArray of sorted $route\ intervals$;\}
\end{itemize}
\end{ttfamily}
The DBArray of \dt{ugpoint} is consistent with the data model of
\cite{NetworkGueting}.
The $drivenDist$ is the total length of all \dt{ugpoint} in the \dt{mgpoint}.
The DBArray of $route\ intervals$ represents all network positions ever traversed
by the \dt{mgpoint}. The flag indicates if the $trajectory$ is well defined,
because this attribute is not maintenanced in every operation changing
\dt{mgpoint} values. And the minimum spatio-temporal bounding box $mbr$ can be
used for a preselection in spatio-temporal queries.

Why this extensions?
Now, analogous to sorted \dt{gline} values the $trajectory$ value makes it much
faster to decide whether an \dt{mgpoint} ever passed a given network position or
not. Instead of a linear check of all $m$ units of an \dt{mgpoint} we can perform
a binary scan on the much smaller number $r$ of the passed $route\ intervals$.
This reduces the time complexity from O($m$) to O($\log r$) for the operations
like \op{passes}.

The spatio-temporal minimum bounding box was introduced as an attribute to the
\dt{mgpoint} because the computation of this value is very expensive in the
NDM. Although each unit of an \dt{mgpoint} stays on the same route
at the same speed it may follow different spatial directions. For example, a
route may lead uphill in serpentine. A spatial bounding box only computed from
the spatial start and end position may not enclose all spatial positions of the
car within the unit. Therefore we always have to examine the spatial dimensions
of the $route\ interval$ passed within a unit to compute the units bounding box
using algorithm \ref{alg:unitbbox}.
\begin{algorithm}[H]
  \caption{\op{Berechnung Unit Bounding Box}}
  \label{alg:unitbbox}
  \begin{algorithmic}[1]
    \STATE Get route curve usint B-Tree index of $routes$ relation
    \STATE Extract subline of unit from route curve
    \STATE Compute bounding box of subline
    \STATE Add third dimension from unit time interval
  \end{algorithmic}
\end{algorithm}
If the number of routes in the $routes$ relation is $R$ the first step has a
time complexity of O($\log R$) time. If the route curve $r_i$ consists of $l_i$
line segments the time complexity of step 2 and 3 is O($l_i$) in the worst case.
Step 4 is done in O(1) time. Together we get a time complexity of
O($\log {R} + l_i$) to compute the bounding box of a single unit.

To compute the $mbr$ this computation must be done for each of the $m$ units of
the \dt{mgpoint} value. That takes O($m \log {R} + \sum_{i=1}^{m}{l_i}$) time.

The time complexity can be reduced if the $trajectory$ is defined. We can use
the $r$ $route\ intervals$ of the $trajectory$ similar to the $m$ units of
the \dt{mgpoint} to compute the spatial bounding box. The third dimension can be
added using the start and the end time instant of the \dt{mgpoint} value. This a
algorithm has a time complexity of O($r \log {R} + \sum_{i=1}^{r}{l_i}$), with
$r \ll m$ in nearly all cases.

But the computation is still expensive. So the $mbr$ is only computed on demand
or if we can get it for free. For example we can copy
the bounding box of an \dt{mpoint} at the translation time into an \dt{mgpoint}
in O(1) time.
Analogous to the $trajectory$ the $mbr$ is not maintained. If
the \dt{mgpoint} value changes, the $mbr$ is set to be undefined until recomputing
is necessary.

\subsection{Indexes in Network Environment}
\label{sec:implNetIndex}
Spatial and spatio-temporal bounding boxes are used to support for spatial
and spatio-temporal indexing of spatial respectively spatio-temporal positions.
Because of the special problems with spatio-temporal bounding boxes in network
environments (see Section \ref{sec:implNetDataTyp}) we use only for the trip
based approach a spatio-temporal bounding box tree $dataMNtrip\_SpatioTemp$ and
this tree only indexes spatio-temporal bounding boxes for complete \dt{mgpoint}
values. The advantages of more detailed indexes have been outperfomred within
our experimental evaluation of the network implementation for the \bmodb{}.

We introduced Network Bounding Boxes (NBB) and Temporal Network Bounding Boxes
(TNBB) in our implementation to support indexing in terms of network positions
with R-Trees instead of spatial indexing.

Let \dt{ugpoint} and $route\ interval$ be defined like in \ref{sec:netdatamod}.
The NBB of a $route interval$ is defined as $(rid,\ rid,\ pos1,\ pos2)$,
which can be seen as an degenerated two dimensional rectangle.
The TNBB of a \dt{ugpoint} value is defined as
$(rid,\ rid,\ pos1,\ pos2,\ t1,\ t2)$,
which analogous can be seen as an degenerated three dimensional rectangle.

We use these NBB and TNBB to create Network Position Indexes (NPI) and
Temporal Network Position Indexes (TNPI) indexing the network positions of
the \dt{mgpoint} values of the \bmodb{}.

An NPI is an R-Tree build from the NBB
of the $route intervals$ of the $trajectory$ attributes of the \dt{mgpoint}
values.

An TNPI is an R-Tree build from the TNBB of the \dt{ugpoint} values of the
\dt{mgpoint} values.
\subsection{Network Operations used in \bmodb{}}
\label{sec:implNetOperations}
The operations used to construct the network object (\op{thenetwork}), and to
translate spatial and spatio-temporal values into network values are described in
Section \ref{sec:Translation}. In this section we give an overview of the
operations on network objects used in the benchmark queries of the \bmodb{}.

Table \ref{tab:simplenetoperations} gives an overview of the simple benchmark
operations. The more complex operations are described in the sequel.
\begin{sidewaystable}
  \caption{Simple Operations on Network Data Types}
  \label{tab:simplenetoperations}
  %\begin{scriptsize}
  \begin{center}
  \begin{tabularx}{1.0\textwidth}{|l|l|X|X|}
  \hline
  \textbf{Name}& \textbf{Signature}& \textbf{Explanation}& \textbf{Complexity}\\
  \hline
\op{routes}& \dt{network} $\rightarrow$ \dt{relation} & Returns the $routes$
relation fo the \dt{network} object & O($R$)\\
  \hline
\op{no\_components}&\dt{mgpoint} $\rightarrow$ \dt{real}& Returns the number of
units of the \dt{mgpoint} &O(1)\\
  \hline
\op{length}&\dt{mgpoint} $\rightarrow$ \dt{real}& Returns the $length$ of the
argument.&O(1)\\
  \hline
\op{trajectory}&\dt{mgpoint} $\rightarrow$ \dt{gline}& Returns the $trajectory$
of the \dt{mgpoint} value as \dt{gline}&O($r$), if trajectory is defined, O($m \log r + r$) otherwise\\
  \hline
\op{units}&\dt{mgpoint} $\rightarrow$ \dt{stream}(\dt{ugpoint})& Returns a
stream
of the \dt{ugpoint} values of the \dt{mgpoint} value& O($m$)\\
  \hline
\op{initial}&\dt{mgpoint} $\rightarrow$ \dt{igpoint}& Returns the first position
and the start time of the \dt{mgpoint} value& O(1)\\
  \hline
\op{atinstant}&\dt{mgpoint} $\times$ \dt{instant} $\rightarrow$ \dt{igpoint}&
Returns the network position of the \dt{mgpoint} value at the given time instant&
O($\log m$)\\
  \hline
\op{val}&\dt{igpoint} $\rightarrow$ \dt{gpoint}& Returns the \dt{gpoint} of the
\dt{igpoint} value&O(1)\\
  \hline
\op{inst}&\dt{igpoint} $\rightarrow$ \dt{instant}& Returns the time instant of the
\dt{igpoint} value &O(1)\\
  \hline
\op{isempty}&\dt{gline} $\rightarrow$ \dt{bool}& Returns \true{} if the \dt{gline}
has no $route\ intervals$ & O(1)\\
  \hline
\op{routeintervals}&\dt{gline} $\rightarrow$ \dt{stream}(\dt{rectangle})& Returns
the $netbox$ for each $route\ interval$ of the \dt{gline} value& O($r$)\\
  \hline
\op{gpoint2rect}& \dt{gpoint} $\rightarrow$ \dt{rectangle} & Returns a $netbox$
for the \dt{gpoint} value & O(1)\\
\hline
\op{unitbox}& \dt{ugpoint} $\rightarrow$ \dt{rectangle3D} & Returns the $netbox$
of the \dt{ugpoint} & O(1)\\
  \hline
  \end{tabularx}
  \end{center}
  %\end{scriptsize}
\end{sidewaystable}

We use $m$ as the number of units of the \dt{mgpoint} value,
$r$ (resp. $r_1$, $r_2$) as the number of $route\ intervals$ of the \dt{gline}
value or the $trajectory$ attribute of an \dt{mgpoint} value (resp. of the
first, second argument), $R$ as the number of routes in the network object, $l_i$
the number of line segments of a route curve $r_i$,
and $p$ as the number of time intervals in a \dt{periods} value.

For the Euclidean Distance computation we retranslate our network values into
spatial (\op{gline2line}) respectively spatio-temporal (\op{mgpoint2mpoint})
values. In the original paper this operations are called \op{in\_space}.
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{gline} $\rightarrow$ \dt{line} \> \op{gline2line}($gline$) \\
\dt{mgpoint} $\rightarrow$ \dt{mpoint} \> \op{mgpoint2mpoint}($mgpoint$)\\
\end{tabbing}
The operation \op{gline2line} uses the Algorithm \ref{alg:gline2line} to
translate a \dt{gline} value into an \dt{line} value.
\begin{algorithm}[H]
  \caption{\op{gline2line}($gl$)}
  \label{alg:gline2line}
  \begin{algorithmic}[1]
    \FOR {each $route\ interval$ of $gl$}
      \STATE Get route curve of $route\ interval$ using B-Tree index of $routes$ relation
      \STATE Perform binary search on line segments of route curve to find the
      start position of the $route\ interval$
      \STATE Copy line segments to result until end pos of $route\ interval$ is
reached.
    \ENDFOR
    \RETURN resulting line
  \end{algorithmic}
\end{algorithm}
The loop from line 1 to
line 5 is repeated $r$ times. The B-Tree search in line 2 take O($\log{R}$)
time. The binary search in line 3 takes O($\log l_i$) tim. The copy operation in line 4 takes
O($l_i$) time in the worst case. The return of the result has a worst case
time complexity of O($\sum_{i=1}^{r}{l_i}$). For the whole algorithm we
get
\[O(r \log{R} + \sum_{i=1}^{r}{\log{l_i}} + 2\sum_{i=1}^{r}{l_i})
= O(r \log{R} + \sum_{i=1}^{r}{l_i})\].

The operation \op{mgpoint2mpoint} is described by Algorithm
\ref{alg:mgpoint2mpoint}. The loop from line 3 to line 28 is repeated $m$ times. The statements from
line 5 to line 8 take O($\log R + l_i$) every time they are executed. But they
are only executed at the first run of the loop and if the car changes the route.
We have three different cases for the computing of the $mpoint$ units. The
simple cases from line 10-11 and line 13-16 have a time complexity of O(1).
The third case has a worst case complexity from O($l_i$). The last line 29 has a time
complexity of O($m_{res}$) if $m_{res}$ is the number of units of the resulting
\dt{mpoint} value. In the worst case we get a time complexity of
\[O(m \log {R} + \sum_{i=1}^{m}{l_i} + m_{res}).\]
\begin{algorithm}[H]
  \caption{\op{mgpoint2mpoint}($mgp$)}
  \label{alg:mgpoint2mpoint}
  \begin{algorithmic}[1]
    \STATE $actRID$ = -1
    \STATE Initialize resulting $mpoint$
    \FOR{each unit $curUGP$ of $mgp$}
      \IF{not (rid from $curUGP$ == $actRID$)}
        \STATE $actRID$ = rid from $curUGP$
        \STATE $rc$ = route curve of $actRID$
        \COMMENT{$rc$ determined using B-Tree Index of $routes$ relation}
        \STATE Perform binary search on the line segments of $rc$ to find
        line segment $l$ with start position of $curUGP$
        \STATE $upstart$ = x,y-coordinates of start position
      \ENDIF
      \IF{end position == start position}
        \STATE add unit $upstart,\ upstart$ to $mpoint$
      \ELSE
        \IF{end position is on $l$}
          \STATE $upend$ = x,y-coordinates of end position
          \STATE add unit $upstart,\ upend$ to $mpoint$
          \STATE $upstart$ = $upend$
        \ELSE
          \STATE Follow $rc$ in moving direction of $curUGP$
          \WHILE{not(end position is on $l$)}
            \STATE add unit from $upstart$ to $segment\ end\ position$ to
$mpoint$
            \STATE $upstart$ = $segment\ end\ position$
            \STATE $l$ = next segment in moving direction
          \ENDWHILE
          \STATE $upend$ = x,y-coordinates of end position
          \STATE add unit from $upstart$ to $upend$ to $mpoint$
        \ENDIF
      \ENDIF
    \ENDFOR
    \RETURN $mpoint$
  \end{algorithmic}
\end{algorithm}
In the trip based approach (TBA) the result values of the different trips must
be
aggregated to an single result value. Therefore the operation \op{union} was
introduced. \op{union} gets two \dt{gline} values or two \dt{mgpoint} values as
input and mixes them up to a single sorted \dt{gline} or a single \dt{mgpoint}
value.
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{gline} $\times$ \dt{gline} $\rightarrow$ \dt{gline} \> $gline1$ \op{union} $gline2$ \\
\dt{mgpoint} $\times$ \dt{mgpoint} $\rightarrow$ \dt{mgpoint} \> $mgpoint1$ \op{union} $mgpoint2$\\
\end{tabbing}
\begin{algorithm}[H]
  \caption{\op{union}($gl_1$, $gl_2$)}
  \label{alg:uniongline}
  \begin{algorithmic}
    \IF{$gl_1$ is sorted AND $gl_2$ is sorted}
      \STATE Perform parallel scan of $gl_1$ and $gl_2$
      \IF{Current $route\ intervals$ do not intersect}
         \STATE Add smaller $route\ interval$ to result
         \STATE Continue Scan with next $route\ interval$
      \ELSE
          \STATE Merge $route\ intervals$ into one
          \IF{Next $route\ intervals$ intersect the merged one}
            \STATE merge them too
          \ENDIF
          \STATE Add merged $route\ interval$ to result
          \STATE Continue Scan
      \ENDIF
    \ELSE
      \FOR{Each $route\  interval$ of $gl_1$ and $gl_2$}
        \STATE Insert $route\ interval$ into $RITree$
      \ENDFOR
      \STATE Copy sorted $route\ intervals$ from $RITree$ to resulting \dt{gline}
    \ENDIF
    \RETURN resulting \dt{gline}
  \end{algorithmic}
\end{algorithm}
The Algorithm \ref{alg:uniongline} distinguishes between two cases.
If both \dt{gline} values are sorted the algorithm has a time complexity of
O($r_1 + r_2$) and if one or both \dt{gline} are not sorted it has a time
complexity of O($(r_1 + r_2) \log r_{res} + r_{res}$), if $r_{res}$ is the
number of $route\ intervals$ of the resulting \dt{gline}. The additional
time results from sorting and compressing the resulting $route\ intervals$. As
explained before (see Section \ref{sec:implNetDataTyp}) we think that this time
is well invested, because several algorithms take profit from sorted \dt{gline}
values.

The computation of the union of two \dt{mgpoint} values works almost similar to
the \op{union} operation for two sorted \dt{gline}. We perform a parallel scan
through the \dt{mgpoint} values and add the units in the sequel of their time
intervals to the resulting \dt{mgpoint} value. If two units have overlapping time
intervals and the positions of the \dt{ugpoint}s within the overlapping time
interval are not the same the resulting \dt{mgpoint} is not defined, otherwise
one unit is added to the result for the overlapping time interval. The time
complexity of the \op{union} operation is O($m_1 + m_2$).
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{mgpoint} $\rightarrow$ \dt{rect3} \> \op{mgpbbox}($mgpoint$)\\
\end{tabbing}
The operation \op{mgpbbox} returns the spatio-temporal bounding box of an
\dt{mgpoint} value. As explained before (see Section \ref{sec:implNetDataTyp})
the $mbr$ value is not maintained such that the operation \op{mgpbbox} knows
three different cases:
\begin{enumerate}
  \item If the $mbr$ is defined it can be returned in O(1) time.
  \item The $mbr$ is not defined but the $trajectory$ can be used to compute the
$mbr$ the time complexity is O($r \log {R} + \sum_{i=1}^{r}{l_i}$)
  \item If the $mbr$ and $trajectory$ are not defined the time complexity will be
O($m \log {R} + \sum_{i=1}^{m}{l_i}$)
\end{enumerate}
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{mgpoint} $\times$ \dt{periods} $\rightarrow$ \dt{mgpoint} \> $mgpoint$ \op{atperiods} $periods$\\
\end{tabbing}
The operation \op{atperiods} restricts a \dt{mgpoint} value to the given
periods. The operation performs a binary scan of the units of the \dt{mgpoint}
to find the unit including the start time instant of the periods value,
respectively the last unit with an time interval smaller than the start time
instant of the periods value in O($\log m$) time. From that position the $k_i$
units, which have time intervals that intersect with the periods value are
copied to the result in O($k_i$) time\footnote{The first and last time
interval might be splitted at the start (resp. end) time instant of the periods
value.}. The total time complexity of the operation is O($\log {m} + k_i$)
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{mgpoint} $\times$ \dt{periods} $\rightarrow$ \dt{bool} \> $mgpoint$ \op{present} $periods$\\
\end{tabbing}
The operation \op{present} returns \true{} if the \dt{mgpoint} value is
defined at least at one time inside the given \dt{Periods} value, \false{}
otherwise. The algorithm works almost similar to the \op{atperiods} operation, but
the scan of the \dt{mgpoint} units is stopped immediately if a intersecting unit
is found. The worst case time complexity for the operation is O($\log {m} + k_i$).
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{gpoint} $\times$ \dt{gline} $\rightarrow$ \dt{bool} \> $gpoint$ \op{inside} $gline$\\
\dt{mgpoint} $\times$ \dt{gline} $\rightarrow$ \dt{mbool} \> $mgpoint$ \op{inside} $gline$\\
\end{tabbing}
The operation \op{inside} returns \true{} if a \dt{gpoint} is inside a \dt{gline},
\false{} otherwise. For sorted \dt{gline} values the algorithm performs a binary
scan of the $route\ intervals$ to find a $route\ interval$ including the
\dt{gpoint} in O($\log r$) time. For unsorted \dt{gline} values a linear scan of
the $route\ intervals$ is performed in O($r$) time to find an $route\ interval$
including the \dt{gpoint}.
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{mgpoint} $\times$ \dt{gpoint} $\rightarrow$ \dt{bool} \> $mgpoint$ \op{passes} $gpoint$\\
\dt{mgpoint} $\times$ \dt{gline} $\rightarrow$ \dt{bool} \> $mgpoint$ \op{passes} $gline$\\
\end{tabbing}
The operation \op{passes} returns \true{} if a \dt{mgpoint} value passes a
given \dt{gpoint} or \dt{gline} value. The algorithm uses the $trajectory$ of the \dt{mgpoint} value.

For an \dt{gpoint} value a binary scan of the $trajectory$ is performed to find a
$route\ interval$ that includes the \dt{gpoint}. The time complexity of this operation is O($\log r$).

For an \dt{gline} value two cases are distinguished. If the \dt{gline} value is
sorted a parallel scan of the set of
$route\ intervals$ and the $trajectory$ is performed and immediately aborted if
two intersecting $route\ intervals$ have been found. In this case the worst case
time complexity is O($r_1 + r_2$). If the \dt{gline} value is not sorted a linear
scan of the set of $route\ intervals$ of the \dt{gline} is performed and for
every $route\ interval$ a binary scan of the $trajectory$ is performed to find
a intersecting $route\ interval$. In this case the worst case time complexity
is O($r_2 \log {r_1}$).
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{mgpoint} $\times$ \dt{gpoint} $\rightarrow$ \dt{mgpoint} \> $mgpoint$ \op{at} $gpoint$\\
\dt{mgpoint} $\times$ \dt{gline} $\rightarrow$ \dt{mgpoint} \> $mgpoint$ \op{at} $gline$\\
\end{tabbing}
The operation \op{at} restricts a \dt{mgpoint} to the times and places it was
at a given \dt{gpoint} or moved inside a given \dt{gline}.

For \dt{gpoint} values
the operation \op{at} performs a linear scan of all units of the \dt{mgponit}
value. Every time a \dt{ugpoint} passes the \dt{gpoint} the time instant of
passing is computed and the resulting unit is added to the resulting \dt{mgpoint}.
The computation of the result has a time complexity of O($m$).

For \dt{gline} values the algorithm (see Algorithm \ref{alg:at}) distinguishes two
cases. For sorted \dt{gline} values the loop from line 2 to 7 is executed in
O($m \log r$) time.
\begin{algorithm}[H]
  \caption{$mgpoint$ \op{at} $gline$}
  \label{alg:at}
  \begin{algorithmic}[1]
    \IF{$gline$ is sorted}
      \FOR{Each unit of $mgpoint$}
        \STATE Perform binary scan after unit in set of $route\ intervals$ of
 $gline$
        \IF{unit intersects $route\ interval$}
          \STATE Add resulting unit to result
        \ENDIF
      \ENDFOR
    \ELSE
      \FOR {Each unit of $mgpoint$}
        \FOR {Each $route\ interval$ of $gline$}
          \IF{unit intersects $route\ interval$}
            \STATE Compute intersection and add it to result
          \ENDIF
        \ENDFOR
      \ENDFOR
    \ENDIF
    \RETURN result
  \end{algorithmic}
\end{algorithm}
For unsorted \dt{gline} values line 9 to 14 are executed, which needs O($mr$)
time. The result is returned in O($m_{res}$) time in both cases. In case
of sorted \dt{gline} values the total run time is O($m \log {r} + m_{res}$)
and in case of unsorted \dt{gline} values O($mr + m_{res}$).
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{gline} $\times$ \dt{gline} $\rightarrow$ \dt{bool} \> \op{intersects}($gline1$, $gline2$)\\
\end{tabbing}
The operation \op{intersects} returns \true{} if two \dt{gline} values
intersect, \false{} otherwise.
\begin{algorithm}[H]
  \caption{\op{intersects}($gl_1$,$gl_2$)}
  \label{alg:intersectsgline}
  \begin{algorithmic}[1]
     \IF{Both \dt{gline} values are sorted}
       \STATE Perform a parallel scan of the $route\ intervals$ of the both \dt{gline} values
       \IF{$route\ intervals$ intersect}
          \RETURN \TRUE
       \ENDIF
     \ELSE
       \IF{Both \dt{gline} not sorted}
         \FOR{Each $route\ interval$ of $gl_1$}
           \FOR {Each $route\ interval$ of $gl_2$}
              \IF{$route\ intervals$ intersect}
                \RETURN \TRUE
              \ENDIF
           \ENDFOR
         \ENDFOR
       \ELSE
          \FOR{Each $route\ interval$ of the unsorted \dt{gline} value}
            \STATE Perform a binary search on the sorted \dt{gline} value
            \IF{Intersecting $route\ interval$ is found}
              \RETURN \TRUE
            \ENDIF
          \ENDFOR
       \ENDIF
     \ENDIF
     \RETURN \false{}
  \end{algorithmic}
\end{algorithm}
The Algorithm \ref{alg:intersectsgline} differentiates three cases:
\begin{enumerate}
\item If both \dt{gline} values are sorted (see lines 2 to 5) the time complexity
is O($r_1 + r_2)$)
\item If both \dt{gline} values are not sorted (see lines 8 to 14) the time
complexity is O($r_1r_2$)
\item If only one \dt{gline} value is sorted (see lines 16 - 21) the time
complexity is O($r_1 \log r_2$) respectively O($r_2 \log r_1$), depending on
which of the both \dt{gline} values is sorted.
\end{enumerate}
\section{Translation of BerlinMOD into Network Data Model}
\label{sec:Translation}
In this section we describe the creation of the \dt{network} object from the
$streets$ value of the \bmodb{} in Section \ref{sec:createNetwork}. In Section
\ref{sec:translateSTdata} we describe how to use this new created \dt{network}
object in the translation of all spatial and spatio-temporal data objects of the
\bmodb{} into the NET representation.
In Section \ref{sec:createIndex} we describe the indexes we build on the database
use in the NET representation of the \bmodb{} to support faster query execution.
We close this section with Section \ref{sec:queries} a description of our
executable \secondo{} queries for the NET representation of the \bmodb{}.

Executable \secondo{} scripts for the network and index creation, object
translation, and the network benchmark queries can be downloaded from our web
site \cite{NetworkWeb}.
\todo{Create corresponding website!}
\subsection{Create Network Object}
\label{sec:createNetwork}
Before we can use the operator \op{thenetwork} to construct the network object
$net$ for the NET version of the \bmodb{} we have to build the input relations
for \op{thenetwork} from the data generated by the \bmodb{}.

We use the $streets$ object created by the BerlinMOD Data Generator to construct
our input relation $B\_ROUTES$ for the $routes$ relation of $net$. We extract the
routes geometries from the streets relation and add to each route curve a
automatic generated integer number as route identifier. We add fields for the
length of each route curve and and two Boolean values indicating if the route is
dual and start at the smaller end point. If the $streets$ object contains $R$
routes and a route curve of a route $r_i$ has $l_i$ line segments this will take
\[O(R + \sum_{i=1}^{R}{l_i}) = O(\sum_{i=1}^{R}{l_i})\]
time.

In a next step we use $B\_Routes$ to compute the crossings of the street network
of Berlin. Therefore we join all route of $B_Routes$ with intersecting spatial
bounding boxes and filter the routes that really intersect. For this pairs of
routes we compute the positions of the junctions on the route curves and fill
the resulting data in $B\_Junctions$ relation. The relation $B\_Junctions$ has the
attributes: $r1id$, $r1meas$, $r2id$, $r2meas$, and $cc$. The last one is the
connectivity code that should tell which lanes of the two routes are connected
by the junction. But the data source lacks information about the connectivity
of the street crossings, such that we use the maximum value for the connectivity
code of each crossing as default value in this step. This step has a time
complexity of O($R^2$) in the worst case.

Now we can use $B\_Routes$ and $B\_Junctions$ as input relations for our network
constructor \op{thenetwork} to create our \dt{network} object $net$ representing
the streets of Berlin in the NET representation of the \bmodb{}. The attributes
of the $net$ object have been explained in Section \ref{sec:implNetDataTyp}.

Algorithm \ref{alg:thenetwork} describes how $net$ is created from the two input
relations.
\begin{algorithm}[H]
\caption{\op{thenetwork}($nid,\ B\_Routes,\ B\_Junctions$)}
\label{alg:thenetwork}
\begin{algorithmic}[1]
\REQUIRE An unifique integer $nid \geq 0$, $B\_Routes$ and $B\_Junctions$ relation
as described.
\STATE Create Network empty network object $net$ with id $nid$
\STATE Copy $B\_Routes$ to $routes$ relation of $net$
\STATE Construct B-Tree indexing route identifiers in $routes$ relation
\STATE Construct R-Tree indexing route curves in $routes$ relation
\STATE Copy $B\_Junctions$ to $junctions$ relation of $net$ and add route tuple identifiers from routes relation
\STATE Construct B-Trees indexing the first / second route identifiers in the $junctions$ relation
\FOR {Each tuple in $routes$ relation}
  \FOR {Each junction on this route}
    \STATE Compute the $up$ and $down$ sections
    \STATE Add the sections to the $sections$ relation
    \STATE Add the section identifiers to the $junctions$ relation
  \ENDFOR
\ENDFOR
\STATE Construct B-Tree indexing route identifiers in the $sections$ relation
\FOR {Each junction in $junctions$ relation}
  \STATE Find pairs of adjacent sections and fill adjacency list
\ENDFOR
\end{algorithmic}
\end{algorithm}
Let $J$ be the number of entries in $B\_Junctions$. and $j_i$ the number of
junctions on route $r_i$ from the $routes$ relation. The number of entries in the
sections relation of $net$ will be $\sum_{i=1}^{R}({j_i + 1}) = R + \sum_{i=1}^{R}{j_i}$,

The time complexities of the single steps of Algorithm \ref{alg:thenetwork} are:
\begin{itemize}
  \item[] line 1: O(1)
  \item[] line 2: O($R$)
  \item[] line 3 and 4: O($R \log R$)
  \item[] line 5: O($J$)
  \item[] line 6: O($J \log J$)
  \item[] line 7 - 13: O($\sum_{i=1}^{R}{j_i}$)
  \item[] line 14: O($(R + \sum_{i=1}^{R}{j_i}) \log ({R + \sum_{i=1}^{R}{j_i}})$)
  \item[] line 15 - 17: O($J$)
\end{itemize}
For all steps together we get a time complexity of
\begin{align*}
&O(1 + R + R \log R + J + J \log J + R + \sum_{i=1}^{R}{j_i} + (R + \sum_{i=1}^{R}{j_i}) \log (R + \sum_{i=1}^{R}{j_i}) + J)\\
&= O((R + \sum_{i=1}^{R}{j_i}) \log (R  + \sum_{i=1}^{R}{j_i})),
\end{align*}
because $R,\ J \leq R + \sum_{i=1}^{R}{j_i}$.
\subsection{Translate Spatial and Spatio-Temporal Data Types}
\label{sec:translateSTdata}
In this section we describe the translation of the spatial and spatio-temporal
data types of the \bmodb{} data set into network constrained
objects. In the original paper this operations are all called \op{in\_network}.
All translations are done relative to the \dt{network} object $net$ of the
previous section.

All algorithms in this section get a spatial respectively spatio-temporal \bmodb{}
data type object and the corresponding \dt{network} object $net$ as input.
They return the corresponding data type from the network data model NET,
respectively an undefined NET object if the input data object is not constrained
by $net$.
\subsubsection{Translate \dt{point} into \dt{gpoint}}
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{network} $\times$ \dt{point} $\rightarrow$ \dt{gpoint} \> \op{point2gpoint}($net$, $point$)\\
\end{tabbing}
The \op{point2gpoint} operation translates a \dt{point} value $p$ into a
corresponding \dt{gpoint} value $gp$ if possible. Variants of this operation are
also included in the other translation operations. The operations in line 1 to 2 of
Algorithm \ref{alg:point2gpoint} need O(1) time.
\begin{algorithm}[H]
  \caption{\op{point2gpoint}($p$)}
  \label{alg:point2gpoint}
  \begin{algorithmic}[1]
    \STATE $bbox$ = spatial bounding box of $p$
    \STATE $bbox$ = extend bbox by 1.0 in every direction
    \STATE Select set of $candidate\ routes$ using $bbox$ and R-Tree of $routes$ relation
    \STATE $found$ = \false{}
    \WHILE {not $found$ AND not isEmpty(candidateRoutes)}
      \IF {Distance of point from route = 0}
        \STATE found = true
        \STATE Compute position of point on route
      \ENDIF
    \ENDWHILE
    \RETURN corresponding \dt{gpoint} value
  \end{algorithmic}
\end{algorithm}
$Candidate\ routes$ are routes, which spatial minimum bounding boxes intersect
with the spatial bounding box of the \dt{point} value.
The selection of $candidate\ routes$ from the R-tree needs O($\log R + c$) time
if $c$ is the number of $candidate\ routes$ for $p$.
The assignment in line 4 takes O(1) time.
In the worst case the loop from line 5 to line 10 is called $c$ times.
The computation in lines 6 to 8 takes in the worst case O($l_i$) time, because
we have to find the line segment to which $p$ is connected. The result
is returned in O(1) time. We get a worst time complexity of
\[O(\log R + c + \sum_{i=1}^{c}{l_i} + 1) = O(\log R + \sum_{i=1}^{c}{l_i})\]
for the operation \op{point2gpoint}. Let this time complexity be called $o_{P2G}$ in operations using \op{point2gpoint} operation.

In case of the \bmodb{} the $side$ value of $gp$ is always set to $none$,
because the \bmodb{} does not differentiate between the different sides of a street.

This should be all to translate the \dt{point} values of the $QueryPoints$
relation of the \bmodb{} into network query positions. But there is a problem with
the NET representation of junctions. In the NET, contrary to SPACE, each junction
has more than one \dt{gpoint} representation, because each junction is related to
two or more routes. Hence if a junction position is given related to route $a$
we won't detect the junction as passed if an \dt{mgpoint} object passes the junction
on route $b$ in all cases, because the definition of \op{passes} in the network
data model is slightly different from the \op{passes} operation in the \bmodb{}
data model. Unfortunately all query points of the \bmodb{} are junctions. To make
the results comparable, we added an operator \op{polygpoints}, which returns for
every input \dt{gpoint} value $gp$ a stream of \dt{gpoint} values.
\begin{tabbing}
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\dt{gpoint} $\rightarrow$ \dt{stream}(\dt{gpoint}) \> \op{polygpoints}($gpoint$)\\
\end{tabbing}
If $gp$ represents a junction
we return all \dt{gpoint} values representing the same junction in $net$,
otherwise we return only $gp$ in the stream. The Algorithm \ref{alg:polygpoints}
describes the \op{point2gpoint} in detail.
\begin{algorithm}
  \caption{\op{polygpoints}($gp$)}
  \label{alg:polygpoints}
  \begin{algorithmic}[1]
    \STATE Copy $gp$ to output stream
    \STATE Use B-Tree on $junctions$ relation to Get junctions on route $gp.rid$
    \IF{$gp$ is junction}
      \FOR{Each $gpoint$ representing the same junction}
        \STATE Copy $gpoint$ into output stream
      \ENDFOR
    \ENDIF
  \end{algorithmic}
\end{algorithm}
The worst case time complexity of the \op{point2gpoint} operation is
O($\log J + j_i$) if $j_i$ is the number of junctions on route $i$.

In the end we got 221 query \dt{gpoint} values in $QueryPointsNet$ for the 100
query \dt{point} values in $QueryPoints$ and 22 \dt{gpoint} values in
$QueryPoints1Net$ for the 10 \dt{point} values of $QueryPoints1$ of the \bmodb{}.
This means we always have to compute the results for the double number of query
points in our NET representation of the \bmodb{} relativ to SPACE.
\subsubsection{Translate \dt{mpoint} into \dt{mgpoint}}
The second operation \op{mpoint2mgpoint} translates an \dt{mpoint} value $mp$
into an \dt{mgpoint} value $mgp$.
\begin{algorithm}[H]
  \caption{\op{mpoint2mgpoint}($mp$,$net$)}
  \label{alg:mpoint2mgpoint}
  \begin{algorithmic}[1]
    \STATE Initialize empty $mgp$
    \STATE $upoint$ = first unit of $mp$
    \STATE Initialize $ugp$ = $net$ values of $upoint$
    \COMMENT{Uses variant of \op{point2gpoint} for two point on same route}
    \FOR {Each $upoint$ of $mp$}
      \IF {Endpoint of $upoint$ is on same route than $ugpoint$}
        \IF {Direction and speed stay the same}
          \STATE Extend $ugpoint$ to include $upoint$
        \ELSE
          \STATE Add $ugpoint$ to $mgp$
          \STATE Add $route\ interval$ of $ugpoint$ to $RITree$ for $trajectory$
          \STATE $ugpoint$ = $net$ values of $upoint$
        \ENDIF
      \ELSE
        \STATE Add $ugpoint$ to $mgp$
        \STATE Add $route\ interval$ of $ugpoint$ to $RITree$ for $trajectory$
        \STATE Search $upoint$ on adjacent sections route curves
        \STATE Change current route curve to route curve where the $upoint$ has been found
        \STATE $ugpoint$ = $net$ values of $upoint$
      \ENDIF
    \ENDFOR
    \STATE Add $ugpoint$ to $mgpoint$
    \STATE Add $route\ interval$ of $ugpoint$ to $RITree$ for $trajectory$
    \STATE Build $trajectory$ from $RITree$
    \STATE Copy bounding box of $mp$ to $mgp$
    \RETURN $mgp$
  \end{algorithmic}
\end{algorithm}
The main idea of the algorithm (see \ref{alg:mpoint2mgpoint}) is to use the
continuous movement of $mp$ to reduce
computation time. We need the complete \op{point2gpoint} operation only for the
first unit of the \dt{mpoint} value. After that we can use the found route curve
for computing the network position until the car changes the route. And if the
car changes the route it can only drive on routes which are adjacent to the last
used section, such that we only have to check the route curves of the adjacent
sections instead of searching in the R-Tree for a route curve containing the
current position.

Let $l_{xi},\ 1 \leq x \leq 2$ the number of line segments of route curve $r_i$,
and $s_i$ the number of route curves of adjacent sections of a section $i$
\footnote{Each section has one route curve but two adjacent sections of a section may have the same route curve.}.
The steps of the Algorithm \ref{alg:mpoint2mgpoint} of the \op{mpoint2mgpoint}
operation have the following time complexities:
\begin{itemize}
  \item[] line 1 + 2: O(1)
  \item[] line 3: O($o_{P2G}$)
  \item[] line 4 - 20: Loop will be called $m_{in}$ times and knows three cases
  \begin{itemize}
    \item[] line 5: O($l_{1i}$)
    \begin{enumerate}
      \item: 6 + 7: O(1)
      \item line 9 - 11: O($\log r + l_{1i}$)
      \begin{itemize}
        \item[] line 9: O(1)
        \item[] line 10: O($\log r$)
        \item[] line 11: O($l_{1i}$)
      \end{itemize}
      \item line 14 - 18: O($\log r + \sum_{i=1}^{s_i}{l_{2i}} + l_{1i}$)
      \begin{itemize}
        \item[] line 14: O(1)
        \item[] line 15: O($\log r$)
        \item[] line 16: O($\sum_{i=1}^{s_i}{l_{2i}}$)
        \item[] line 17: O(1)
        \item[] line 18: O($l_{1i}$)
      \end{itemize}
    \end{enumerate}
  \end{itemize}
  \item[] line 21: O(1)
  \item[] line 22: O($\log r$)
  \item[] line 23: O($r$)
  \item[] line 24: O($m_{res}$)
\end{itemize}
The worst case time complexity for the whole algorithm is
\begin{align*}
&O(o_{P2G} + m_{in}(l_{1i} + \log r + \sum_{i=1}^{s_i}{l_{2i}} + l_{1i}) + r + \log r + m_{res})\\
&= O(o_{P2G}+ m_{in}\log r + m_{in}\sum_{i=1}^{s_i}{max(l_{1i},\ l_{2i})} + m_{res})
\end{align*}
\subsubsection{Translate \dt{region} into \dt{gline}}
The translation of the \dt{region} values in the $QueryRegions$ relation of the
\bmodb{} into sorted \dt{gline} values of NET is described in Algorithm
\ref{alg:region2gline}.
\begin{algorithm}[H]
  \caption{Translate \dt{region} values into sorted \dt{gline} values}
  \label{alg:region2gline}
  \begin{algorithmic}[1]
     \STATE Build single line object $rl$ from the route curves of $routes$ relation
     \FOR {Each $region$ of $QueryRegions$}
        \STATE $lreg$ = intersection of $region$ and $rl$
        \STATE $netRegion$ = \op{line2gline}($lreg$)
     \ENDFOR
  \end{algorithmic}
\end{algorithm}
The step in line 1 has a time complexity of O($\sum_{i=1}^{R}{l_i}$). The loop is
called for each entry in $QueryRegions$. In case of \bmodb{} this will be 100 times.
The intersection of an \dt{region} value with a \dt{line} value is computed by
a planesweep algorithm using an AVL-Tree for the segments. Therefore line 3 has a time
complexity of O($\sum_{i=1}^{R}{l_i} \log \sum_{i=1}^{R}{l_i}$). The operation
\op{line2gline} in line 4 uses Algorithm \ref{alg:line2gline} and has therefore
a time complexity of
\[O(l_{1i} o_{P2G} + l_{1i} \log r + r)\]
\begin{algorithm}
  \caption{\op{line2gline}($l$, $net$)}
  \label{alg:line2gline}
  \begin{algorithmic}[1]
    \FOR{Each line segment $l_i$ of $l$}
      \STATE Use variant of \op{point2gpoint} to find $route\ curve$ including $l_i$
      \STATE Insert corresponding $route\ interval$ into $RITree$
    \ENDFOR
    \RETURN sorted and compressed \dt{gline} value from $RITree$
  \end{algorithmic}
\end{algorithm}
For the whole translation operation we get a worst case time complexity of
\begin{align*}
& O(\sum_{i=1}^{R}{l_i} + (\sum_{i=1}^{R}l_i) \log (\sum_{i=1}^{R}{l_i}) + l_{1i} o_{P2G}+ l_{1i} \log r + r)\\
& = O((\sum_{i=1}^{R}{l_1i}) \log (\sum_{i=1}^{R}{l_1i}) + l_{1i} o_{P2G}).
\end{align*}
The algorithm is very expensive, because it depends on existing \secondo{} operations.
This is acceptable for the current use with the \bmodb{},
because the 100 regions are fixed and only translated once in the data generation
step. It is planned to implement a own efficient translation operation for region
values for latter use cases.
\subsection{Created Indexes for NET Representation}
\label{sec:createIndex}
For the use with the \bmodb{} we created the indexes of Table \ref{tab:NETIndexes} on the NET representation of the \bmodb{} data sets.
\begin{table}[H]
  \caption{Indexes on NET Representation of \bmodb{}}
  \label{tab:NETIndexes}
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Name of Index}& \textbf{Explanation}\\
    \hline
    $dataSNcar\_licence\_btree$& B-Tree on $licences$ in $dataSNcar$ relation.\\
    \hline
    $dataMcar\_licence\_btree$& B-Tree on $licences$ in $dataMcar$ relation.\\
    \hline
    $dataMcar\_Moid\_btree$& B-Tree on $moid$ in $dataMcar$ relation.\\
    \hline
    $dataMNtrip\_Moid\_btree$& B-Tree on $moid$ in $dataMNtrip$ relation.\\
    \hline
    $dataSNcar\_BoxNet\_timespace$ & TNPI on $trip$ in $dataSNcar$ \\
    \hline
    $dataMNtrip\_BoxNet\_timespace$ & TNPI on $trip$ in $dataMNtrip$\\
    \hline
    $dataSNcar\_TrajBoxNet$ & NPI on $trip$ in $dataSNcar$\\
    \hline
    $dataMNtrip\_TrajBoxNet$ & NPI on $trip$ in $dataMNtrip$\\
    \hline
    $dataSNcar\_SpatioTemp$ & R-Tree on the spatio-temporal bounding box of $trip$ in $dataSNcar$\\
    \hline
    $dataMNtrip\_SpatioTemp$ & R-Tree on the spatio-temporal bounding box of $trip$ in $dataMNtrip$\\
    \hline
  \end{tabularx}
\end{table}

The B-Tree indexes for the $licences$ and $moid$ attributes of the relations
$dataSNcar$, $dataMcar$, and $dataMNtrip$ are similar to the indexes
created in the \bmodb{} for $dataSCcar$, $dataMCcar$, and $dataMCtrip$,
respectively. We don't explain them in more detail.

The Network Position Index (NPI) and the Temporal Network Position Index (TNPI)
are new constructions. They are used in query processing to support a faster
selection of \dt{mgpoint} values that passed given network positions or network
regions at / within a given time (TNPI) or without temporal restrictions (NPI).
Detailed explanations of the trees and their construction can be found in
Section \ref{sec:implNetIndex}.

The R-Tree indexes of the spatio-temporal bounding boxes of the $trip$ attributes
in $dataMNtrip$ and t$dataSNcar$ relation are different from the
R-Trees of spatio-temporal bounding boxes used in the \bmodb{}.
In the NET representation only the big bounding boxes of the whole trips inserted
in the indexes, whereas in SPACE  representation the much smaller bounding boxes
for each single unit are inserted. This is done because the computation of the
small bounding boxes in NET representation is very expensive (see Section
\ref{sec:implNetDataTyp}). It takes several hours to build the spatio-temporal
unit bounding box indexes for the \dt{mgpoint}  values at the smallest scalefactor.
For bigger scalefactors we stopped the attempt of computation after several days,
because we think that the results of the current used indexes are not so bad that
the additional build time is well invested. We don't expect a great improvement
of query run times.
\subsection{Translate Benchmark Queries}
\label{sec:queries}
\todo[caption={queries appendix}]{Really senseful this way? Move formal queries to Appendix.}
We developed executable \secondo{} queries for each of the 17 BerlinMOD/R queries
for the OBA and the TBA using our network indexes to support faster query execution.
The \secondo{} optimizer is not able to optimize SQL-queries on NDM objects yet, so we tested in
our experiments many different query formulations for each query to get optimal
queries delivering the correct result in a minimum of time.

The limited space does not allow us to show all our executable \secondo{} queries
for the NDM in detail, but they can be downloaded as \secondo{} scripts
from our web page. Here we give only a short overview over the \bmodb{} queries
and their NDM algorithms.

Every time we need a licence in the result or have a query licence number we need
an additional step in the TBA, because we have to join the $dataMNtrip$ and $dataMcar$
relation using the $moid$ attribute and the corresponding B-Tree indexes.
We will not repeat this step at every single TBA query description.

Query 1 asks for the models of the cars with licence plate numbers from $QueryLicences$,
and query 2 for the number of vehicles that are ``passenger cars''. Both queries
deal only with standard attributes; so we only changed the relation names and the
B-Tree indexes to match the NDM representation.

Query 3 searches for the positions of the ten cars from $QueryLicence1$ at the
ten time instants from $QueryInstants1$. We use the licence B-Tree to select the
ten cars and compute the positions of these ten cars for each of the ten time
instants from $QueryInstants1$ if the time instant is inside the definition time
of the trip.

Query 4 asks for the licence numbers of the cars that passed the points
from $QueryPointsNet$. We create a $netbox$ for each \dt{gpoint} in $QueryPointNet$
and use our specialised $netbox$ R-Tree of the \dt{mgpoint} \dt{RouteInterval} to
select the vehicles passing the given query points.

The queries 5, 6, and 10 deal with Euclidean distance values, which are not very
useful in network environments. In networks everything is constrained by the
network and normaly the network distances are computed instead of Euclidean
distances. We decided to retranslate intermediate results
into spatial respectively spatio-temporal objects and use the existing
Euclidean distance operation to compute the distances between this objects to make
the results comparable.

Query 5 asks for the minimum distance between places where vehicles with
licences from $QueryLicence1$ and $QueryLicence2$ have been. We select the cars
with licence plate numbers from $QueryLicence1$ respectively $QueryLicences2$ using the
B-Tree over the $Licence$ attribute of the $dataSNcar$ relation. In the TBA, the
resulting trajectories for each car are aggregated into one single trajectory
for each car. In both approaches we create a \dt{line} value for each resulting
(aggregated) trajectory value of the \dt{mgpoint}s and compute the Euclidean distance
between these \dt{line} values for each pair of licences one from $QueryLicences1$ and one
from $QueryLicences2$.

Query 6 asks for the pairs of licences from ``trucks'' that have been as close as
10m or less to each other. We filter $dataSNcar$ relation, respectively $dataMcar$
relation to select the ``trucks'' and compute the spatio-temporal bounding box
of each trip of a ``truck''. We extend the spatial dimensions of the bounding boxes
by 5m in each spatial direction and retranslate the \dt{mgpoint} values into \dt{mpoint}
values in a first step. In a second step, we compute join the results from
step one with itself using the intersection of the bounding boxes as join criteria.
We filter the result to include all licence pairs of ``trucks'' that had sometimes
a distance lower than 10m. In the TBA, we additionally remove the duplicate licence
pairs from the result.

Query 7 asks for the licence plate numbers of the ``passenger'' cars that reached
the points from $QueryPoints$ first of all ``passenger'' cars during the
observation period. The first step to solve query 7 in the NDM is
equal to query 4. In a filter step we remove all ``not passenger'' cars from the
first intermediate result. We compute for each remaining candidate trip the times
the trip reaches first the query positions. We group the resulting time instants
by the identifiers of the query positions and compute the minimum time stamp of
each group, which is in fact the first time the query position was reached by a
car. In a last step the licences of the ``passenger'' cars reaching the query
positions at this first time instant are computed using the specialised
network-temporal index of the NDM.

Query 8 computes the overall travelled distances of the vehicles from $QueryLicence1$
within the periods from $QueryPeriods1$. We select the candidate cars using the
licence B-Tree, restrict the trips to the query periods and return the lengths of the
trips in the OBA. In the TBA we have to sum up the length of the different
trips driven by a single car within each query period.

Query 9 asks for the longest distance travelled by a single vehicle during each
of the periods from $QueryPeriods1$. We restrict all trips to the periods, compute
the driven distances and select the maximum length for each query periods value.
Again we have to do an additional aggregation of the distances driven from the same
car in the same period in the TBA.

Query 10 asks when and where vehicles with licences from $QueryLicence1$ meet which
other vehicles (distance less than 3m). In the OBA we first retranslate every
\dt{mgpoint} value of $dataSNCar$ into a \dt{mpoint} value and extend the spatial
bounding box of each of this trips by 1.5 m in every spatial direction. After that we
select the ten candidate trips given by $QueryLicences1$, retranslate them and
extend their spatial bounding boxes in the same way. We join all trips from the
first two steps where the extended bounding boxes intersect and filter the
candidate pairs that have different licences and their distance is sometimes
less than 3m to each other. We compute the position of the \dt{mgpoint} at the
times the distance between the remaining candidate pairs of \dt{mpoint} was less
than 3 m and return the licence pairs and the network positions of the first car
when it has been closer than 3 m to the other one.

In the TBA we select the trips given by $QueryLicences1$ from
$dataMNtrip$, retranslate them into \dt{mpoint} values, and extend their spatio-temporal
bounding boxes by 3m in each spatial direction. After that we use the spatio-temporal
index of $dataMNtrip$ to select for each trip of the ten cars, the cars
of $dataMNtrip$ which spatio-temporal bounding boxes intersect the extended spatio-temporal
bounding boxes built before. For every pair of candidate trips we
retranslate the second trip and use the Euclidean Distance function for \dt{mpoint}
values to determine the times when the both \dt{mgpoint} had a distance less than 3m.
At last we restrict the trip of the query \dt{mgpoint} to this times and
aggregate the resulting trips into one single trip for each licence pair.

In our experiments we tried out several indexes to support a faster query execution
of query 10 including the MON-Tree presented in \cite{MONTreeAlmeidaGeoinformatica}. The MON-Tree showed
very good CPU times but never the less the total run time was very high. In the end
the simple form described above showed the best complete run time performance of all
indexes.

Query 11 asks for the vehicles that passed a point from $QueryPoints1Net$ at one of the
time instants from $QueryInstants1$. We build a network-temporal query box from the
$QueryInstant1$ and $QueryPoints1Net$ relation and use the network-temporal index
on $dataSNcar$, respectively $dataMNtrip$, to select the resulting trips.

Query 12 asks for the vehicles that met at a point from $QueryPoints1Net$ at an time
instant from $QueryInstants1$. The first step of query 12 is identical with query 11.
In a second step the Cartesian Product of the result of the first step with itself
is computed and filtered for vehicles which have been at the same query point
at the same query time instant.

Query 13 asks for the vehicles which travelled within one of the regions from
$QueryRegions1Net$ during the periods from $QueryPeriods1$. We restrict the trips
to the query regions and check if the restricted trips are defined within the query
periods. In TBA possible duplicate licence pairs have to be removed and the
resulting $moid$s must be mapped to the licences of the cars to generate the result
using the B-Tree $moid$ index of $dataMcar$.

Query 14 asks for the vehicles that have been in one of the regions from $QueryRegions1Net$
at a time instant from $QueryInstants1$. We build temporal-netboxes from the query
objects to select candidate trips using the temporal-network position index. We refine the
result filtering the candidate trips really full filling the query predicates.

Query 15 asks for the vehicles passing a point from $QueryPoints1Net$ during a period
from $QueryPeriods1$. Analogous to query 14 we build temporal-netboxes of the
of the query parameters to select the candidate trips using the temporal-network
position index and refine the result filtering the candidates really fullfilling
the query constraints.

Query 16 asks for the licence pairs one from $QueryLicence1$ and one from $QueryLicence2$
of vehicles, which were both present in a region from $QueryRegions1Net$ within a period
from $QueryPeriods1$, but did not meet there and then. We select the candidate trips
using the licence B-Tree of $dataSNcar$ relation and restrict the resulting trips to be
\op{present} during the query periods and \op{inside} the query region. This is done
one time for the licences from $QueryLicences1$ and one time for the licences from
$QueryLicences2$. The both intermediate results are joined and filtered to get the
trips of different cars which where at the same period in the same region
without meeting each other there and then. In the TBA we have
to do a additional selection from trips with the $moids$ belonging to the cars
selected before by the licences and remove duplicates of licence pairs from the
same period and region.

Query 17 asks for the points from $QueryPointsNet$ that have been visited by a
maximum number of different vehicles. In a first step we use almost the query
algorithm from query 4 to select the trips passing a given query
point. After that we group the cars passing query points by the ids of the
query points and count the number of cars passing this query point. In a last
step the point(s) with the maximum number of passing cars is(are) selected.
In the TBA we have to remove duplicate vehicles from the result list before we
count the number of passing cars.
\section{Experimental Setup}
\label{sec:scenario}
\todo[caption={NET SPACE}]{Controll this and next section for right use of NET and SPACE instaed of old abbreviations.}
For our experiments we used a standard personal computer with an AMD Phenom II X4
Quad Core 2.95 GHz CPU, 8 GB main memory, and 2 TB hard disk. We installed the
Linux openSUSE 11.2 as operating system, \secondo{} DBMS version 3.0, and
the \bmodb{} version provided in the web.
\todo[caption={Website}]{Provide scripts in web and add link to scripts!}

We generated three databases with different amounts of data using the data generation
script of the \bmodb{} with the $scalefactor$ 0.05, 0.2, and 1.0. The following
steps are done with all three databases. We first created the \bmodb{} data and indexes
using the script ``BerlinMOD\_CreateObjects.SEC'' for the DMFS. The NDM
representation of the databases was generated by the the script ``Network\_CreateObjects.SEC''
that uses the algorithms and builds the indexes described in Section \ref{sec:Translation}.

Table \ref{tab:dbstat} shows the created amounts of data for the different $scalefactor$
values in both data models. As you can see, the NDM needs less
than 40\% of the storage space of the \bmodb{} data model. The main cause is that
the same trip is represented by less than 50\% of the units in the NDM
compared to the DMFS. This is a very good result and we expect this effect to
increase if the cars make long distance
trips instead of moving in a single town like they do in the benchmark. In towns
cars more often change the street or the velocity than cars that do long distance
trips and so the compact route representation in the NDM should become
more effective than in the town.
\begin{table}[H]
\begin{center}
\begin{scriptsize}
\begin{tabularx}{1.0\textwidth}{|X|c|c|c|c|c|c|}
\hline
&\multicolumn{2}{c|}{\textbf{Scalefactor 0.05}}&\multicolumn{2}{c|}{\textbf{Scalefactor 0.2}}&\multicolumn{2}{c|}{\textbf{Scalefactor 1.0}}\\
\hline
Number of Cars&\multicolumn{2}{c|}{447}&\multicolumn{2}{c|}{894}&\multicolumn{2}{c|}{2000}\\
\hline
Number of Days&\multicolumn{2}{c|}{6}&\multicolumn{2}{c|}{13}&\multicolumn{2}{c|}{28}\\
\hline
Data Generation&\multicolumn{2}{c|}{164.761s}&\multicolumn{2}{c|}{587.299s}&\multicolumn{2}{c|}{3177.46s}\\
\hline
&DFMS&NDM&DFMS&NDM&DFMS&NDM\\
\hline
Data Translation
and Index Build&301.72s&535.65s&1,362.72s&2,190.45s&7,419.13s&11,144.13s\\
\hline
Number of Units&2,646,026&1,260,888&11,296,682&5,346,971&52,140,685&24,697,709\\
\hline
Total Storage Space&2.26 GB&0.86 GB&9.51 GB&3.69 GB&45,76 GB&17.28 GB\\
Data&0.79 GB&0.44 GB&3.35 GB&1.83 GB&15.47 GB& 8.40 GB\\
Indexes&1.48 GB&0.42 GB&6.16 GB&1.86 GB&30.30 GB&8.89 GB\\
\hline
\end{tabularx}
\end{scriptsize}
\caption{Database Statistics}
\label{tab:dbstat}
\end{center}
\end{table}
The long creation time of the NDM representation is
caused by the expensive mapping of spatial and spatio-temporal positions into
network positions. The indexes themselves are built faster in the network representation
than in the \bmodb{} representation because they have less entries and are smaller.

We found some isolated mismatches in some query results as we compared the results
of the \bmodb{} queries and the NDM queries for the OBA and the TBA. We detected
that the source data of the street map of the \bmodb{} is not well defined in all places.
Figure \ref{fig:routefailure} shows two examples for the street map failures. Using
a very high zoom factor you can see that single streets consist of more than one
line. We corrected the source file ``streets.data'' of the \bmodb{} at the places
where we detected the errors and restarted the building of the databases and our
experiments from scratch. With the corrected street map, all results match
each other in the different data models and approaches.
\begin{figure}[H]
\begin{center}
   \includegraphics[scale=1.0]{routefailure.eps}
   \caption{Example Failures in Street Map}
   \label{fig:routefailure}
   \end{center}
\end{figure}
\section{Experimental Results}
\label{sec:results}
We repeated the \bmodb{} query execution several times for both data models and
approaches. The tables in Figure \ref{fig:compruntimes} and the graphic in
\ref{fig:CompTotalRunTimesGraphic} compare the average query run times in seconds
for the different scale factors, data models, and approaches.
As you can see, the total run time of all queries in the NDM is around
50\% less than the total query run time of the DMFS at each scale factor.
\begin{figure}[h]
  \begin{minipage}{0.5\linewidth}
    \begin{tiny}
      \begin{tabular}{|c|r|r|r|r|}
        \hline
        &\multicolumn{4}{c|}{\textbf{Scalefactor 0.05}}\\
        \cline{2-5}
        &\multicolumn{2}{c|}{\textbf{DMFS}}&\multicolumn{2}{c|}{\textbf{NDM}}\\
        \hline
        \textbf{Query}&\textbf{OBA}&\textbf{TBA}&\textbf{OBA}&\textbf{TBA}\\
        \hline
        \textbf{1}&0.125&0.109&0.128&0.088\\
        \hline
        \textbf{2}&0.003&0.002&0.003&0.002\\
        \hline
        \textbf{3}&0.245&0.205&0.227&0.268\\
        \hline
        \textbf{4}&6.594&7.514&0.238&0.846\\
        \hline
        \textbf{5}&1.072&1.585&1.098&1.031\\
        \hline
        \textbf{6}&14.332&6.280&3.995&3.675\\
        \hline
        \textbf{7}&3.458&3.191&3.893&3.192\\
        \hline
        \textbf{8}&0.353&0.379&0.201&0.205\\
        \hline
        \textbf{9}&96.724&166.434&19.840&21.783\\
        \hline
        \textbf{10}&104.239&31.555&62.972&76.826\\
        \hline
        \textbf{11}&0.150&0.096&0.224&0.443\\
        \hline
        \textbf{12}&0.296&0.120&0.202&0.226\\
        \hline
        \textbf{13}&9.959&6.551&1.094&1.113\\
        \hline
        \textbf{14}&0.516&0.659&1.566&1.709\\
        \hline
        \textbf{15}&1.144&0.857&0.579&0.488\\
        \hline
        \textbf{16}&6.214&14.354&0.612&1.483\\
        \hline
        \textbf{17}&1.126&0.719&0.228&0.262\\
        \hline
        \textbf{Total}&246.551&240.609&97.061&113.640\\
        \hline
      \end{tabular}
    \end{tiny}
  \end{minipage} \hfill
  \begin{minipage}{0.5\linewidth}
    \begin{tiny}
      \begin{tabular}{|c|r|r|r|r|}
        \hline
        &\multicolumn{4}{c|}{\textbf{Scalefactor 0.2}}\\
        \cline{2-5}
        &\multicolumn{2}{c|}{\textbf{DMFS}}&\multicolumn{2}{c|}{\textbf{NDM}}\\
        \hline
        \textbf{Query}&\textbf{OBA}&\textbf{TBA}&\textbf{OBA}&\textbf{TBA}\\
        \hline
        \textbf{1}&0.123&0.096&0.157&0.099\\
        \hline
        \textbf{2}&0.003&0.003&0.008&0.003\\
        \hline
        \textbf{3}&0.501&0.327&0.424&0.349\\
        \hline
        \textbf{4}&32.323&39.113&0.500&6.522\\
        \hline
        \textbf{5}&1.657&2.985&2.394&2.198\\
        \hline
        \textbf{6}&57.453&45.931&15.508&13.451\\
        \hline
        \textbf{7}&17.184&11.150&27.084&22.814\\
        \hline
        \textbf{8}&0.390&0.379&0.205&0.220\\
        \hline
        \textbf{9}&250.626&386.452&36.323&46.187\\
        \hline
        \textbf{10}&447.679&126.870&286.779&287.101\\
        \hline
        \textbf{11}&0.247&0.165&2.119&2.958\\
        \hline
        \textbf{12}&4.171&0.182&0.262&0.316\\
        \hline
        \textbf{13}&27.028&12.106&5.865&4.669\\
        \hline
        \textbf{14}&1.125&1.143&8.783&9.101\\
        \hline
        \textbf{15}&7.800&3.874&2.543&1.876\\
        \hline
        \textbf{16}&6.441&25.298&0.362&0.776\\
        \hline
        \textbf{17}&8.722&4.042&0.289&0.641\\
        \hline
        \textbf{Total}&863.472&660.217&389,605&399.281\\
        \hline
      \end{tabular}
    \end{tiny}
  \end{minipage}\hfill
\begin{minipage}{0.5\linewidth}
    \begin{tiny}
      \begin{tabular}{|c|r|r|r|r|}
        \hline
        &\multicolumn{4}{c|}{\textbf{Scalefactor 1.0}}\\
        \cline{2-5}
        &\multicolumn{2}{c|}{\textbf{DMFS}}&\multicolumn{2}{c|}{\textbf{NDM}}\\
        \hline
        \textbf{Query}&\textbf{OBA}&\textbf{TBA}&\textbf{OBA}&\textbf{TBA}\\
        \hline
        \textbf{1}&0.196&0.186&0.387&0.185\\
        \hline
        \textbf{2}&0.005&0.004&0.006&0.004\\
        \hline
        \textbf{3}&0.731&0.483&1.020&1.349\\
        \hline
        \textbf{4}&150.172&157.629&2.089&31.769\\
        \hline
         \textbf{5}&3.274&6.079&5.230&5.494\\
        \hline
        \textbf{6}&826.483&2002.002&270.468&235.594\\
        \hline
        \textbf{7}&99.086&53.099&118.840&125.206\\
        \hline
        \textbf{8}&0.794&0.524&0.254&0.398\\
        \hline
        \textbf{9}&775.458&2263.531&106.910&143.150\\
        \hline
        \textbf{10}&3314.518&1942.155&2150.250&1645.812\\
        \hline
        \textbf{11}&0.685&0.474&6.080&7.889\\
        \hline
        \textbf{12}&37.445&0.200&0.272&0.290\\
        \hline
        \textbf{13}&111.587&72.907&26.880&32.540\\
        \hline
        \textbf{14}&11.397&4.238&36.728&37.700\\
        \hline
        \textbf{15}&28.512&16.862&9.696&8.602\\
        \hline
        \textbf{16}&9.726&53.011&0.571&1.880\\
        \hline
        \textbf{17}&86.357&152.542&0.530&6.884\\
        \hline
        \textbf{Total}&5456.427&6725.924&2736.210&2284.747\\
        \hline
      \end{tabular}
    \end{tiny}
  \end{minipage}
 \caption{Compare Query Run Times in Seconds}
 \label{fig:compruntimes}
\end{figure}
\begin{figure}
  \includegraphics[width=1.0\linewidth]{compruntimesall.eps}
  \caption{Compare Total Run Times}
  \label{fig:CompTotalRunTimesGraphic}
\end{figure}

For the queries 1 and 2, the query run times are almost the same for all data models
and approaches at the different scale factors. This is what we expected because
both queries deal only with standard attributes and standard indexes, which
are not influenced by the different data models.

For query 3, the run times for all data models and approaches are very small. But
we can see a development of the ratio of the run times between the different
data amounts, data models and approaches. Although the query algorithms for both
data models and approaches are almost the same, the run time ratio for the different
amounts of data is different. For the small databases (scale factor 0.05 and 0.2)
the NDM outperforms in the OBA the DMFS, while for scalefactor 1.0 and all TBA
queries the DMFS outperforms the NDM. We think that
two different effects take place. On the one hand, the number of units in the NDM
is less than the number of units in the DMFS,
such that the unit which contains the query time instant can be found faster.
On the other hand, a \dt{gpoint} value has more internal elements (3 \dt{int}, 1 \dt{real},
and 1 \dt{bool}) than a \dt{point} value (2 \dt{real}, and 1 \dt{bool}), such
that result computing and copying is a little more expensive in the NDM.
The advantage of the smaller number of units in a binary search is smaller if
the number of units becomes bigger and the disadvantage of bigger results becomes
greater; that explains the different run time ratios for query 3.

In query 4 the NDM outperforms the DMFS
significantly at all scale factors ($>$ 2 min OBA, $>$ 6 min TBA at scale factor 1.0).
The NDM index used in query 4 is much smaller (OBA 24 MB, TBA 160 MB, at scalefactor 1.0)
than the spatial unit index of the \bmodb{} (OBA 3.7 GB, TBA 3.7 GB at scalefactor 1.0)
and more precise, such that we do not need an additional refinement step after the
index usage in the NDM, like we do in the DMFS.

We expected the NDM to be slower than the DMFS in the queries 5,6, and 10, because
we retranslate intermediate results from the NDM representation into the DMFS representation.
For query 5 this holds in the OBA. We need a little more time in the NDM
than in the DMFS. But in TBA the NDM outperforms the DMFS. This is due to the fact
that a \dt{gline} value has less \dt{RouteInterval}s
than a \dt{line} value representing the same part of a curve has \dt{HalfSegment}s,
such that the union of two or more \dt{gline} values in the aggregate step of query 5 in
TBA can be computed much faster than the union of two or more \dt{line} values.

The NDM outperforms the DMFS again significantly at query 6
for all amounts of data and approaches. In the NDM we reduce the number of candidate
pairs for the distance computation by pre selecting intersecting extended bounding boxes
and use the operation \op{notEverNearerThan} in OBA and TBA, while in the DMFS
in the OBA no filtering is used and the computation is done by
\op{minimum}(\op{distance}($mp1$,$mp2$)$\leq$10.0), and in the TBA the operation
\op{spatialjoin} is used instead of bounding box intersection. While the operation
\op{distance} has always a run time O($n$) the operation \op{everNearerThan}
stops computation immediately if the distance between two units is less than the
query value to reduce computation time. And the operation \op{spatialjoin} of the
\secondo{} DBMS seems to have a big weakness in implementation. Otherwise the
difference in the TBA query run times could not be so big ($>$ 17 min OBA, $>$
80 min TBA, at scale factor 1.0).\todo{check analysis for correctness.}

After the very good results from query 4 we did not expect query 7 to have such
results in the run times comparison. In fact at scalefactor 1.0 the DMFS outperforms
the NDM significantly in both
approaches and at all scale factors in TBA, while at the smaller scale factors in
OBA the NDM outperforms the DMFS. We think there are two main causes: On the one hand we
have to do the expensive operation \dt{at} for \dt{mgpoint} for the double number
of query \dt{gpoint} compared with the DMFS and
on the other hand the test points out a weakness of the NDM
implementation of the operation \op{at} for \dt{mgpoint}. But in the end, NDM looses
at scale factor 1.0 less than 45 seconds in the OBA respectively less
than 120 seconds in TBA, what is not much compared with the advantages in the
other benchmark queries.

Query 8 is a very fast query in both data models, although the query run time of
the NDM is more than 50\% less than the query run time of the
DMFS. This is caused by the
$length$ attribute of the \dt{mgpoint} and the smaller number of units of a
\dt{mgpoint} compared with the corresponding \dt{mpoint}.

For query 9, the NDM outperforms the DMFS by orders of magnitude. The advantages
named in the analysis of query 8's run time results have a much higher impact
when the number of examined trips becomes bigger. At scale factor 1.0 this saves
more than 10 min time in the OBA and more than 50 min time in the TBA.

The ratio of the run times of query 10 changes between the amounts of data and
both data models. In the OBA and at scale factor 1.0 in the TBA the NDM outperforms
the DMFS at all scale factors, while in the TBA at the two small databases the
DMFS outperforms the NDM significantly. Before our experiments we expected that
the DMFS would outperform the NDM in all cases, because of the expensive
retranslation of intermediate results. So why is the NDM faster ($>$ 20 min in
OBA and $>$ 3 min in TBA at scale factor 1.0) than the DMFS?
In the OBA we use bounding boxes for a preselect of candidate trips that step is not
performed in the DMFS. In the TBA the results are only better for the big amounts
of data we think this is due to the fact that the number of units in \dt{mgpoint}
values is always smaller than in \dt{mpoint} values such that the final aggregation
of the different trips of the same cars can be done faster in the NDM
than in the DMFS.

Query 11 is identical with the first part of query 12. So it is surprising that
the run time of query 11 at scalefactor 1.0 is longer than the run time of query 12,
which does additional computations. In our experiments with the different queries
we have seen that there exist numerous cache effects depending on the sequence of
the queries. So we think that query 12 takes profit cache effects resulting from
query 11 running immediately before query 12. Another weakness of the NDM pointed
out by the run times of query 11 and query 14 is that our
network-temporal position index has bad run times for query $netbox$ objects
constructed from a single \dt{gpoint} and a single time instant. This becomes worse
with a higher number of indexed units. As you can see at query 15 this does not
hold for query $netboxes$ constructed from a single \dt{gpoint} and a time interval.
We have to spend some more work to figure out the problem and develop a better
network-temporal position index to improve our NDM system.

In our experiments we also tested the MON-Tree \cite{MONTreeAlmeidaGeoinformatica} as network-temporal
index but the elapsed run time performance was not good, although the CPU run times
was were small.

The bad performance of the network-temporal position index is also shown by query 13.
The NDM outperforms the DMFS significantly, but we do not use any index in the
executable NDM queries, while the DMFS uses its spatio-temporal index to preselect
candidate trips. The same holds for query 17.

The NDM version of query 16 takes profit from the smaller number
of units in the NDM and outperforms the data model of free movement
in two dimensional space.

Although we detected in our experiments some points of weakness in the network-temporal
position indexing, the NDM outperforms the DMFS by orders of magnitude. The weakness
of the NDM mostly occurs in queries with short run times, whereas the advantages
of the NDM become apparent in the queries with long run times, such that the weakness
of the network-temporal position index is covered by the advantages of the network
data model.
\section{Summary and Future Work}
\label{sec:summary}
We presented our translation of the \bmodb{} into the NDM and
compared the capabilities of both data models, with very good results for the
NDM. Our experiments show that the NDM outperforms
the DMFS by orders of magnitude with respect to storage space and query run times.
This is mainly caused by the much lower number of units for an \dt{mgpoint} value
compared with the number of units of the corresponding \dt{mpoint}, which also
results in smaller indexes for the NDM objects. The \bmodb{} of the NDM pointed out
that we should spend time in the improvement of the network-temporal position index
and the \op{at} operation for \dt{mgpoint} and \dt{gpoint} values.

The good results of the NDM encourage us to work on an extension
of the \bmodb{}, which should enable us to compare the capabilities of different
spatio-temporal NDMs with respect to the special challenges of
NDM, like shortest path and fastest path computation.

Another direction of our actual work is traffic flow estimation and traffic jam
representation in the NDM.

Another interesting topic for future work on the NDMs is the efficient
computation of dynamic network distances between moving network objects.
\bibliography{BerlinMODAndNetworkDataModel}{}
\bibliographystyle{plain}
\appendix
\section{Executable \secondo{} Queries}
In the sequel we present our executable \secondo{} queries for the NET representation
of the \bmodb{}. The name of the query result object indicates the number of
the query, and it is a query for the object based approach (OBA), or for the
trip based approach (TBA).
\begin{scriptsize}
\begin{tabbing}
xxx\=xxx\=xxx\=xxx\=xxx\=xxx\=xxx\=xxx\=xxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\kill
\op{let} Q1OBA =\\
\>QueryLicences \op{feed} \{l\}\\
\>\>\op{loopjoin} [dataSNcar\_Licence\_btree dataSNcar \op{exactmatch} [.Licence\_l]]\\
\>\>\op{project} [Licence, Model]\\
\op{consume};\\
\\
\op{let} Q1TBA =\\
\>QueryLicences \op{feed} \{l\}\\
\>\>\op{loopjoin} [dataMcar\_Licence\_btree dataMcar \op{exactmatch}[.Licence\_l]]\\
\>\>\op{project} [Licence, Model]\\
\op{consume};\\
\\
\op{let} Q2OBA = dataSNcar \op{feed filter} [.Type = 'passenger'] \op{count};\\
\\
\op{let} Q2TBA = dataMcar \op{feed filter} [.Type = 'passenger'] \op{count};\\
\\
\op{let} Q3OBA =\\
\>QueryLicences1 \op{feed} \{l\}\\
\>\>\op{loopjoin} [dataSNcar\_Licence\_btree dataSNcar exactmatch [.Licence\_l]]\\
\>\>\op{project} [Licence, Trip]\\
\>QueryInstant1 \op{feed} \{i\}\\
\>\op{product}\\
\>\op{projectextend}[Licence, Instant\_i; Pos: \op{val}(.Trip \op{atinstant} .Instant\_i)]\\
\op{consume};\\
\\
\op{let} Q3TBA =\\
\>QueryLicences1 \op{feed} \{l\}\\
\>\>\op{loopsel}[dataMcar\_Licence\_btree dataMcar \op{exactmatch}[.Licence\_l] \{ll\}]\\
\>\>\op{loopjoin}[dataMNtrip\_Moid\_btree dataMNtrip
\op{exactmatch}[.Moid\_ll]]\\
\>QueryInstant1 \op{feed} \{i\}\\
\>\op{symmjoin} [.Trip \op{present} ..Instant\_i]\\
\>\op{projectextend}[Instant\_i, Licence\_ll; Pos: \op{val}(.Trip
\op{atinstant} .Instant\_i)]\\
\op{consume};\\
\\
\op{let} Q4OBA =\\
\> QueryPointsNet \op{feed projectextend}[Id, Pos; Prect: \op{gpoint2rect}(.Pos)]\\
\>\op{loopjoin}[dataSNcar\_TrajBoxNet \op{windowintersectsS}[.Prect]\\
\>\>\>\op{sort rdup} dataSNcar \op{gettuples}]\\
\>\op{project} [Id, Licence]\\
\>\op{sortby} [Id \op{asc}, Licence \op{asc}]\\
\>\op{krdup} [Id, Licence]\\
\op{consume};\\
\\
\op{let}Q4TBA =\\
\>QueryPointsNet \op{feed projectextend}[Id; Elem: \op{gpoint2rect}(.Pos)]\\
\>\op{loopjoin}[dataMNtrip\_TrajBoxNet \op{windowintersectsS}[.Elem]\\
\>\>\>\op{sort rdup} dataMNtrip \op{gettuples}]\\
\>\op{project} [Moid, Id]\\
\>\op{loopsel}[\op{fun}(t:TUPLE) dataMcar\_Moid\_btree dataMcar \op{exactmatch}[attr(t, Moid)]\\
\>\>\op{projectextend}[Licence; Id: attr(t,Id)]]\\
\>\op{sortby} [Id \op{asc}, Licence \op{asc}]\\
\>\op{krdup}[Id, Licence]\\
\op{consume};\\
\\
\op{let} Q5OBA = \\
\>QueryLicences1 \op{feed} \{l1\}\\
\>\>\op{loopsel}[dataSNcar\_Licence\_btree dataSNcar \op{exactmatch} [.Licence\_l1]\\
\>\>\>\op{projectextend}[Licence; TrajLine: \op{gline2line}(\op{trajectory}(.Trip))]]\{c1\}\\
\>QueryLicences2 \op{feed} \{l2\}\\
\>\>\op{loopsel}[dataSNcar\_Licence\_btree dataSNcar \op{exactmatch} [.Licence\_l2]\\
\>\>\>\op{projectextend}[Licence; TrajLine: \op{gline2line}(\op{trajectory}(.Trip))]]\{c2\}\\
\>\op{product}\\
\>\op{projectextend} [Licence\_c1, Licence\_c2; Distance: \op{distance}(.TrajLine\_c1, .TrajLine\_c2)]\\
\op{consume};\\
\\
\op{let} Q5TBA =\\
\>QueryLicences1 \op{feed project}[Licence] \{LL1\}\\
\>\>\op{loopsel}[\op{fun} (t:TUPLE) dataMcar\_Licence\_btree dataMcar \op{exactmatch}[attr(t,Licence\_LL1)] \{CAR\}\\
\>\>\>\op{loopsel}[dataMNtrip\_Moid\_btree dataMNtrip exactmatch[.Moid\_CAR]]\\
\>\>\>\op{projectextend}[;Traj: \op{trajectory}(.Trip)]\\
\>\>\>\op{aggregateB}[Traj; \op{fun} (L1: gline, L2: gline) L1 \op{union} L2; [const gline value ()]]\\
\>\>\>\op{feed namedtransformstream}[Traxj]\\
\>\>\>\op{extend}[Licence: attr(t,Licence\_LL1)]]\\
\>\>\op{projectextend}[Licence; Trax: \op{gline2line}(.Traxj)]\{c1\}\\
\>QueryLicences2 \op{feed} \op{project}[Licence] \{LL2\}\\
\>\>\op{loopsel}[\op{fun} (s:TUPLE) dataMcar\_Licence\_btree dataMcar \op{exactmatch}[attr(s,Licence\_LL2)] \{CAR\}\\
\>\>\>\op{loopsel}[dataMNtrip\_Moid\_btree dataMNtrip \op{exactmatch}[.Moid\_CAR]]\\
\>\>\>\op{projectextend}[;Traj: \op{trajectory}(.Trip)]\\
\>\>\>\op{aggregateB}[Traj; \op{fun} (L3: gline, L4: gline) L3 \op{union} L4; [const gline value ()]]\\
\>\>\>\op{feed namedtransformstream}[Traxj]\\
\>\>\>\op{extend}[Licence: attr(s,Licence\_LL2)]]\\
\>\>\op{projectextend}[Licence; Trax: \op{gline2line}(.Traxj)]\{c2\}\\
\>\op{product}\\
\>\op{projectextend}[Licence\_c1, Licence\_c2; Distance: \op{distance}(.Trax\_c1, .Trax\_c2)]\\
\op{consume};\\
\\
\op{let} Q6hOBA =\\
\>dataSNcar \op{feed filter} [.Type = 'truck']\\
\>\op{projectextend} [Licence; ptrip: \op{mgpoint2mpoint}(.Trip), BBox: \op{mgpbbox}(.Trip)]\\
\>\op{projectextend} [Licence, ptrip; Box: \op{rectangle3}(\op{minD}(.BBox,1) - 5.0, \op{maxD}(.BBox,1) + 5.0,\\
\>\>\>\>\op{minD}(.BBox,2) - 5.0, \op{maxD}(.BBox,2) + 5.0,\op{minD}(.BBox,3), \op{maxD}(.BBox,3))]\\
\op{consume};\\
\op{let} Q6OBA =\\
\>Q6hOBA \op{feed} \{a\}\\
\>Q6hOBA \op{feed} \{b\}\\
\>\op{symmjoin}[(.Box\_a \op{intersects} ..Box\_b) \op{and} (.Licence\_a $<$
..Licence\_b) \op{and}\\
\>\>\>\>(\op{everNearerThan}(.ptrip\_a, ..ptrip\_b, 10.0))]\\
\>\op{project} [Licence\_a, Licence\_b]\\
\>\op{sortby} [Licence\_a \op{asc}, Licence\_b \op{asc}]\\
\>\op{krdup} [Licence\_a, Licence\_b]\\
\op{consume};\\
\op{delete} Q6hOBA;\\
\\
\op{let} Q6hTBA =\\
\>dataMcar \op{feed filter} [.Type = 'truck'] \op{project} [Licence, Moid]
\{c\}\\
\>\op{loopjoin}[dataMNtrip\_Moid\_btree dataMNtrip \op{exactmatch}[.Moid\_c]]\\
\>\op{projectextend} [;Licence: .Licence\_c, BBox: \op{mgpbbox}(.Trip), ptrip: \op{mgpoint2mpoint}(.Trip)]\\
\>\op{projectextend} [Licence, ptrip; Box: \op{rectangle3}((\op{minD}(.BBox,1) - 5.0), (\op{maxD}(.BBox,1) + 5.0),\\
\>\>\>\>(\op{minD}(.BBox,2) - 5.0), (\op{maxD}(.BBox,2) + 5.0), \op{minD}(.BBox,3), \op{maxD}(.BBox,3))]\\
\op{consume};\\
\op{let} Q6TBA =\\
\>Q6hTBA \op{feed} \{c1\}\\
\>Q6hTBA \op{feed} \{c2\}\\
\>\op{symmjoin}[(.Box\_c1 \op{intersects} ..Box\_c2) \op{and} (.Licence\_c1 < ..Licence\_c2)]\\
\>\op{filter} [\op{everNearerThan}(.ptrip\_c1, .ptrip\_c2, 10.0)]\\
\>\op{project} [Licence\_c1, Licence\_c2]\\
\>\op{sortby} [Licence\_c1 \op{asc}, Licence\_c2 \op{asc}]\\
\>\op{krdup} [Licence\_c1, Licence\_c2]\\
\op{consume};\\
\op{delete} Q6hTBA;\\
\\
\op{let} Q7OBA =\\
\>QueryPointsNet \op{feed projectextend}[Id, Pos; Prect: \op{gpoint2rect}(.Pos)] \{a\}\\
\>QueryPointsNet \op{feed projectextend}[Id, Pos; Prect: \op{gpoint2rect}(.Pos)]\\
\>\>\op{loopsel}[\op{fun} (t:TUPLE) dataSNcar\_TrajBoxNet \op{windowintersectsS}[attr(t,Prect)]\\
\>\>\>\>\op{sort rdup} dataSNcar \op{gettuples}\\
\>\>\>\op{filter}[.Type = 'passenger']\\
\>\>\>\op{projectextend}[; Id: attr(t,Id) , Instant: \op{inst}(\op{initial}(.Trip \op{at} attr(t,Pos)))]]\\
\>\>\>\op{filter}[\op{not}(\op{isempty}(.Instant))]\\
\>\>\>\op{sortby}[Id \op{asc}, Instant \op{asc}]\\
\>\>\>\op{groupby}[Id; FirstTime: \op{group feed min}[Instant]]\{b\}\\
\>\op{symmjoin}[.Id\_a = ..Id\_b]\\
\>\op{projectextend}[Id\_a, FirstTime\_b, Pos\_a; MBR: \op{box3d}(.Prect\_a, .FirstTime\_b)]\\
\>\op{loopjoin}[dataSNcar\_BoxNet\_timespace \op{windowintersectsS}[.MBR]\\
\>\>\>\>\op{sort rdup} dataSNcar \op{gettuples}]\\
\>\op{filter}[.Type = 'passenger']\\
\>\op{projectextend}[Licence, FirstTime\_b, Id\_a; Instant: \op{inst}(\op{initial}(.Trip \op{at} .Pos\_a))]\\
\>\op{filter}[\op{not}(\op{isempty}(.Instant))]\\
\>\op{filter}[.Instant $\leq$ .FirstTime\_b]\\
\>\op{project}[Id\_a, Licence]\\
\op{consume};\\
\\
\op{let} Q7hTBA =\\
\>QueryPointsNet \op{feed projectextend}[Id, Pos; Prect: \op{gpoint2rect}(.Pos)]\\
\>\op{loopsel}[\op{fun} (t:TUPLE) dataMNtrip\_TrajBoxNet \op{windowintersectsS}[attr(t,Prect)]\\
\>\>\>\>\op{sort rdup} dataMNtrip \op{gettuples}\\
\>\>\op{loopjoin}[dataMcar\_Moid\_btree dataMcar \op{exactmatch} [.Moid]\\
\>\>\>\op{filter}[.Type = 'passenger']\\
\>\>\>\op{project}[Licence] \{X\}]\\
\>\>\op{projectextend}[ Licence\_X;TimeAtPos: \op{inst}(\op{initial}(.Trip \op{at} attr(t,Pos))), Id: attr(t, Id)]]\\
\>\op{sortby} [Id \op{asc}, TimeAtPos \op{asc}]\\
\op{consume};\\
\op{let} Q7TBA =\\
\>Q7hTBA \op{feed} \{a\}\\
\>Q7hTBA \op{feed groupby} [Id; FirstTime: \op{group feed min}[TimeAtPos]]\{b\}\\
\>\op{symmjoin}[(.Id\_a = ..Id\_b)]\\
\>\op{filter}[.TimeAtPos\_a $\leq$ .FirstTime\_b]\\
\>\op{project} [Id\_a, Licence\_X\_a]\\
\>\op{sortby} [Id\_a \op{asc}, Licence\_X\_a \op{asc}]\\
\>\op{krdup} [Id\_a, Licence\_X\_a]\\
\op{consume};\\
\op{delete} Q7hTBA;\\
\\
\op{let} Q8OBA =\\
\>QueryLicences1 \op{feed} \{l\}\\
\>\>\op{loopsel} [dataSNcar\_Licence\_btree dataSNcar \op{exactmatch}
[.Licence\_l]]\\
\>QueryPeriods1 \op{feed filter}[\op{not}(\op{isempty}(.Period))] \{p\}\\
\>\op{product}\\
\>\op{projectextend} [Licence, Period\_p; Distance: \op{length}(.Trip
\op{atperiods} .Period\_p)]\\
\op{consume};\\
\\
\op{let} Q8TBA =\\
\>QueryLicences1 \op{feed} \{l\}\\
\>\>\op{loopjoin}[dataMcar\_Licence\_btree dataMcar
\op{exactmatch}[.Licence\_l]]\\
\>\>\op{project}[Licence, Moid]\\
\>\>\op{loopsel}[\op{fun} (t:TUPLE) dataMNtrip\_Moid\_btree dataMNtrip
\op{exactmatch}[attr(t, Moid)]\\
\>\>\>\op{projectextend}[Trip; Licence: attr(t,Licence)]]\\
\>QueryPeriods1 \op{feed}\\
\>\op{symmjoin} [.Trip \op{present} ..Period]\\
\>\op{projectextend} [Licence, Period, Id; Distance: \op{length}(.Trip
\op{atperiods} .Period)]\\
\>\op{sortby} [Id \op{asc}, Licence \op{asc}, Distance \op{desc}]\\
\>\op{groupby}[Id, Period, Licence; Dist: \op{group feed sum}[Distance]]\\
\>\op{project}[Licence, Period, Dist]\\
\op{consume};\\
\\
\op{let} Q9OBA =\\
\>dataSNcar \op{feed} \{c\}\\
\>QueryPeriods \op{feed filter}[\op{not}(\op{isempty}(.Period))]\{p\}\\
\>\op{product}\\
\>\op{projectextend} [Id\_p, Period\_p, Licence\_c; Dist: \op{length}(.Trip\_c
\op{atperiods} .Period\_p)]\\
\>\op{sortby} [Id\_p \op{asc}, Period\_p \op{asc}, Dist \op{desc}]\\
\>\op{groupby} [Id\_p, Period\_p; Distance: \op{group feed max}[Dist]]\\
\>\op{project} [Id\_p, Period\_p, Distance]\\
\>\op{sortby} [Id\_p \op{asc}]\\
\>\op{project} [Period\_p, Distance]\\
\op{consume};\\
\\
\op{let} Q9TBA =\\
\>dataMNtrip \op{feed} \{c\}\\
\>QueryPeriods \op{feed filter}[\op{not}(\op{isempty}(.Period))]\{p\}\\
\>\op{symmjoin}[.Trip\_c \op{present} ..Period\_p]\\
\>\op{projectextend} [Moid\_c, Period\_p, Id\_p; Distance: \op{length}(.Trip\_c
\op{atperiods} .Period\_p)]\\
\>\op{sortby} [Id\_p \op{asc}, Moid\_c \op{asc}, Distance \op{desc}]\\
\>\op{groupby} [Id\_p, Period\_p, Moid\_c; Dist: \op{group feed
sum}[Distance]]\\
\>\op{groupby}[Id\_p, Period\_p; Dista: \op{group feed max}[Dist]]\\
\>\op{project}[Period\_p, Dista]\\
\op{consume};\\
\\
\op{let} Q10OBA =\\
\>dataSNcar \op{feed}\\
\>\>\op{projectextend}[Licence; TripA: \op{mgpoint2mpoint}(.Trip), BBox:
\op{mgpbbox}(.Trip)]\\
\>\>\op{projectextend}[Licence, TripA; Box: \op{rectangle2}((\op{minD}(.BBox,1)
- 1.5), (\op{maxD}(.BBox,1) + 1.5),\\
\>\>\>\>(\op{minD}(.BBox,2) - 1.5), (\op{maxD}(.BBox,2) + 1.5))]\{c1\}\\
\>QueryLicences1 \op{feed}\\
\>\>\op{loopsel}[dataSNcar\_Licence\_btree dataSNcar
\op{exactmatch}[.Licence]]\\
\>\>\op{projectextend}[Licence, Trip;  BBox: \op{mgpbbox}(.Trip)]\\
\>\>\op{projectextend}[Licence, Trip; TripA: \op{mgpoint2mpoint}(.Trip), Box:
\op{rectangle2}(\op{minD}(.BBox,1) - 1.5),\\
\>\>\>\>(\op{maxD}(.BBox,1) + 1.5), (\op{minD}(.BBox,2) - 1.5),
(\op{maxD}(.BBox,2) + 1.5))] \{c2\}\\
\>\op{symmjoin}[.Box\_c1 \op{intersects} ..Box\_c2]\\
\>\op{filter} [.Licence\_c1 $\neq$ .Licence\_c2]\\
\>\op{filter} [\op{everNearerThan}(.TripA\_c1, .TripA\_c2, 3.0)]\\
\>\op{projectextend} [Licence\_c1, Licence\_c2; \\
\>\>\>\>Pos: .Trip\_c2 \op{atperiods deftime}((\op{distance}(.TripA\_c1,
.TripA\_c2) $<$ 3.0) \op{at} \true{}]\\
\>\op{filter} [\op{not}(\op{isempty}(.Pos))]\\
\>\op{project} [Licence\_c2, Licence\_c1, Pos]\\
\>\op{sortby} [Licence\_c2 \op{asc}, Licence\_c1 \op{asc}]\\
\op{consume};\\
\\
\op{let} Q10TBA =\\
\>QueryLicences1 \op{feed project}[Licence] \{V1\}\\
\>\op{loopsel}[\op{fun} (t:TUPLE) dataMcar\_Licence\_btree dataMcar
\op{exactmatch}[attr(t,Licence\_V1)]\\
\>\>\op{project}[Moid]\\
\>\>\op{loopjoin}[dataMNtrip\_Moid\_btree dataMNtrip
\op{exactmatch}[.Moid] \op{remove}[Moid]] \{V3\}\\
\>\>\op{extend}[t3bbx: \op{mgpbbox}(.Trip\_V3)]\\
\>\>\op{extend}[ptripA: \op{mgpoint2mpoint}(.Trip\_V3)]\\
\>\>\op{loopjoin}[\op{fun} (u:TUPLE) dataMNtrip\_SpatioTemp
\op{windowintersectsS}[\op{rectangle3}(\\
\>\>\>\>\op{minD}(attr(u,t3bbx),1) - 3.0, \op{maxD}(attr(u,t3bbx),1) + 3.0,\\
\>\>\>\>\op{minD}(attr(u,t3bbx),2) - 3.0, \op{maxD}(attr(u,t3bbx),2) + 3.0,\\
\>\>\>\>\op{minD}(attr(u,t3bbx),3), \op{maxD}(attr(u,t3bbx),3))]\\
\>\>\>\op{sort rdup} dataMNtrip \op{gettuples}\\
\>\>\>\op{filter} [.Moid $\neq$ attr(u, Moid\_V3)]\\
\>\>\>\op{projectextend} [Moid; ptripB: \op{mgpoint2mpoint}(.Trip)]\\
\>\>\>\op{filter} [\op{everNearerThan}(attr(u, ptripA), .ptripB, 3.0)]\\
\>\>\>\op{projectextend}[Moid; Times: \op{deftime}((\op{distance}(attr(u,
ptripA), .ptripB) $<$ 3.0) \op{at} \true{})]\\
\>\>\>\op{filter}[\op{not}(\op{isempty}(.Times))]\\
\>\>\>\op{loopjoin}[dataMcar\_Moid\_btree dataMcar
\op{exactmatch}[.Moid] \op{project}[Licence]]]\\
\>\>\op{projectextend}[Times, Trip\_V3; QueryLicence: attr(t,Licence\_V1),
OtherLicence: .Licence]\\
\>\>\op{projectextend}[QueryLicence, OtherLicence; Pos: .Trip\_V3
\op{atperiods} .Times]\\
\>\>\op{filter}[\op{not}(\op{isempty}(.Pos))]]\\
\>\op{sortby}[QueryLicence \op{asc}, OtherLicence \op{asc}]\\
\>\op{groupby}[QueryLicence, OtherLicence; AllPos: \op{group feed}\\
\>\>\>\op{aggregateB}[Pos; \op{fun} (M1:mgpoint, M2:mgpoint) M1 \op{union} M2;
[const mgpoint value()]]]\\
\>\op{project}[QueryLicence, OtherLicence, AllPos]\\
\op{consume};\\
\\
\op{let} Q11bOBA =\\
\>QueryInstant1 \op{feed} \{i\}\\
\>QueryPoints1Net \op{feed projectextend}[Id, Pos; Prect:
\op{gpoint2rect}(.Pos)]\{p\}\\
\>\op{product}\\
\>\op{projectextend}[Id\_p, Instant\_i; Box: \op{box3d}(.Prect\_p,
.Instant\_i)]\\
\>\op{loopsel}[\op{fun}(t:TUPLE) dataSNcar\_BoxNet\_timespace
\op{windowintersectsS}[attr(t,Box)]\\
\>\>\op{sort rdup} dataSNcar \op{gettuples}\\
\>\>\op{projectextend} [Licence; Id: attr(t,Id\_p), Instant\_i:
attr(t,Instant\_i)]]\\
\op{consume};\\
\\
\op{let} Q11TBA =\\
\>QueryInstant1 \op{feed} \{i\}\\
\>QueryPoints1Net \op{feed projectextend}[Id, Pos; Prect:
\op{gpoint2rect}(.Pos)]\{p\}\\
\>\op{product}\\
\>\op{loopsel}[\op{fun} (t:TUPLE) dataMNtrip\_BoxNet\_timespace
\op{windowintersectsS}[\\
\>\>\>\op{box3d}(attr(t,Prect\_p), attr(t,Instant\_i))]\\
\>\>\op{sort rdup} dataMNtrip \op{gettuples}\\
\>\>\op{projectextend}[Moid; Id: attr(t,Id\_p), Instant:
attr(t,Instant\_i)]]\{a\}\\
\>\op{loopjoin}[dataMcar\_Moid\_btree dataMcar \op{exactmatch}[.Moid\_a]]\\
\>\op{project}[Id\_a, Instant\_a, Licence]\\
\>\op{sortby} [Id\_a \op{asc}, Instant\_a \op{asc}, Licence \op{asc}]\\
\>\op{krdup} [Id\_a, Instant\_a, Licence]\\
\op{consume};\\
\\
\op{let} Q12hOBA =\\
\>QueryInstant1 \op{feed} \{i\}\\
\>QueryPoints1Net \op{feed projectextend}[Id, Pos; Prect:
\op{gpoint2rect}(.Pos)]\{p\}\\
\>\op{product}\\
\>\op{loopsel}[ \op{fun} (t:TUPLE) dataSNcar\_BoxNet\_timespace
windowintersectsS[\\
\>\>\>\op{box3d}(attr(t,Prect\_p), attr(t,Instant\_i))]\\
\>\>\op{sort rdup} dataSNcar \op{gettuples}\\
\>\>\op{projectextend} [Licence; Id\_p: attr(t,Id\_p), Pos\_p: attr(t,Pos\_p),
Instant\_i: attr(t,Instant\_i)]]\\
\>\op{sortby} [Id\_p \op{asc}, Instant\_i \op{asc}, Licence \op{asc}]\\
\op{consume};\\
\op{let} Q12OBA =\\
\>Q12hOBA \op{feed} \{c1\}\\
\>Q12hOBA \op{feed} \{c2\}\\
\>\op{symmjoin} [(.Licence\_c1 $<$ ..Licence\_c2) \op{and} (.Id\_p\_c1 =
..Id\_p\_c2) \op{and} (.Instant\_i\_c1 = ..Instant\_i\_c2)]\\
\>\op{project} [Id\_p\_c1, Pos\_p\_c1, Instant\_i\_c1, Licence\_c1,
Licence\_c2]\\
\>\op{sortby} [Id\_p\_c1 \op{asc}, Instant\_i\_c1 \op{asc}, Licence\_c2
\op{asc}]\\
\op{consume};\\
\op{delete} Q12hOBA;\\
\\
\op{let} Q12hTBA =\\
\>QueryPoints1Net \op{feed projectextend}[Id, Pos; Prect:
\op{gpoint2rect}(.Pos)]\{p\}\\
\>QueryInstant1 \op{feed} \{i\}\\
\>\op{product}\\
\>\op{projectextend} [Id\_p, Pos\_p, Instant\_i; Box: \op{box3d}(.Prect\_p,
.Instant\_i)]\\
\>\op{loopsel}[\op{fun} (t:TUPLE) dataMNtrip\_BoxNet\_timespace
\op{windowintersectsS}[attr(t,Box)]\\
\>\>\op{sort rdup} dataMNtrip \op{gettuples}\\
\>\>\op{projectextend}[Moid; Id: attr(t,Id\_p), Instant:
attr(t,Instant\_i)]]\{a\}\\
\>\op{loopjoin}[dataMcar\_Moid\_btree dataMcar \op{exactmatch}[.Moid\_a]]\\
\>\op{projectextend}[Moid, Licence; Id: .Id\_a, Instant: .Instant\_a]\\
\op{consume};\\
\op{let} Q12TBA =\\
\>Q12hTBA \op{feed} \{A\}\\
\>Q12hTBA \op{feed} \{B\}\\
\>\op{symmjoin} [(.Id\_A = ..Id\_B) \op{and} (.Instant\_A = ..Instant\_B) \op
{and} (.Moid\_A $<$ ..Moid\_B)]\\
\>\op{project} [Id\_A, Instant\_A, Licence\_A, Licence\_B]\\
\>\op{sortby} [Id\_A \op{asc}, Instant\_A \op{asc}, Licence\_B \op{asc}]\\
\op{consume};\\
\op{delete} Q12hTBA;\\
\\
\op{let} Q13OBA =\\
\>dataSNcar \op{feed} \{c\}\\
\>QueryRegions1Net \op{feed filter}[\op{not}(\op{isempty}(.Region))] \{r\}\\
\>\op{symmjoin}[.Trip\_c \op{passes} ..Region\_r]\\
\>\op{projectextend}[Licence\_c, Id\_r, Region\_r; Trip: .Trip\_c \op{at}
.Region\_r]\\
\>QueryPeriods1 \op{feed filter}[\op{not}(\op{isempty}(.Period))]\{p\}\\
\>\op{symmjoin} [.Trip \op{present} ..Period\_p]\\
\>\op{projectextend}[Id\_r, Period\_p; Licence: .Licence\_c, Trip: .Trip
\op{atperiods} .Period\_p]\\
\>\op{filter} [\op{no\_components}(.Trip) $>$ 0]\\
\>\op{project} [Id\_r, Period\_p, Licence]\\
\>\op{sortby} [Id\_r \op{asc}, Period\_p \op{asc}, Licence \op{asc}]\\
\op{consume};\\
\\
\op{let} Q13TBA =\\
\>dataMNtrip \op{feed} \{c\}\\
\>QueryRegions1Net \op{feed filter}[\op{not}(\op{isempty}(.Region))] \{r\}\\
\>\op{symmjoin}[.Trip\_c \op{passes} ..Region\_r]\\
\>\op{projectextend}[Moid\_c, Id\_r; Trip: .Trip\_c \op{at} .Region\_r]\\
\>QueryPeriods1 \op{feed filter}[\op{not}(\op{isempty}(.Period))]\{p\}\\
\>\op{symmjoin}[.Trip \op{present} ..Period\_p]\\
\>\op{loopjoin} [dataMcar\_Moid\_btree dataMcar exactmatch[.Moid\_c]]\\
\>\op{project}[Licence, Id\_r, Period\_p]\\
\>\op{sortby} [Id\_r \op{asc}, Period\_p \op{asc}, Licence \op{asc}]\\
\>\op{krdup} [Id\_r, Period\_p, Licence]\\
\op{consume};\\
\\
\op{let} Q14OBA =\\
\>QueryRegions1Net \op{feed filter}[\op{not}(\op{isempty}(.Region))]\\
\>\op{projectextendstream}[Id, Region; Rrect:  \op{routeintervals}(.Region)]
\{r\}\\
\>QueryInstant1 \op{feed} \{i\}\\
\>{product}\\
\>\op{projectextend}[Id\_R, Region\_r, Instant\_i; Box:
\op{box3d}(attr(t,Rrect\_r), attr(t,Instant\_i))]\\
\>\op{loopsel}[\op{fun} (t:TUPLE) dataSNcar\_BoxNet\_timespace
\op{windowintersectsS}[attr(t,Box)]\\
\>\>\op{sort rdup} dataSNcar \op{gettuples}\\
\>\>\op{filter}[(\op{val}(.Trip \op{atinstant} (attr(t,Instant\_i))))
\op{inside} (attr(t,Region\_r))]\\
\>\>\op{projectextend} [Licence;Instant: attr(t,Instant\_i), Id:
attr(t,Id\_r)]]\\
\>\op{sortby} [Id \op{asc}, Instant \op{asc}, Licence \op{asc}]\\
\>\op{krdup}[Id, Instant, Licence]\\
\op{consume};\\
\\
\op{let} Q14TBA =\\
\>QueryRegions1Net \op{feed filter}[\op{not}(\op{isempty}(.Region))]\\
\>\>\op{projectextendstream}[Id, Region; Brect:
\op{routeintervals}(.Region)]\{r\}\\
\>QueryInstant1 \op{feed} \{i\}\\
\>\op{product}\\
\>\op{projectextend}[Id\_r, Region\_r, Instant\_i; Box: \op{box3d}(.Brect\_r,
.Instant\_i)]\\
\>\op{loopsel}[ \op{fun} (t:TUPLE) dataMNtrip\_BoxNet\_timespace
\op{windowintersectsS}[attr(t,Box)]\\
\>\>\op{sort rdup} dataMNtrip \op{gettuples}\\
\>\>\op{filter}[(\op{val}(.Trip \op{atinstant} (attr(t,Instant\_i))))
\op{inside} (attr(t,Region\_r))]\\
\>\>\op{projectextend}[Moid;Instant: attr(t,Instant\_i), Id:
attr(t,Id\_r)]]\{a\}\\
\>\op{loopjoin}[dataMcar\_Moid\_btree dataMcar exactmatch [.Moid\_a]]\\
\>\op{projectextend}[Licence; Id: .Id\_a, Instant: .Instant\_a]\\
\>\op{sortby} [Id \op{asc}, Instant \op{asc}, Licence \op{asc}]\\
\>\op{krdup}[Id, Instant, Licence]\\
\op{consume};\\
\\
\op{let} Q15OBA =\\
\>QueryPoints1Net \op{feed projectextend}[Id, Pos; Prect:
\op{gpoint2rect}(.Pos)] \{p\}\\
\>QueryPeriods1 \op{feed filter}[\op{not}(\op{isempty}(.Period))] \{t\}\\
\>\op{product}\\
\>\op{projectextend}[Id\_p, Pos\_p, Period\_t; Box: \op{box3d}(.Prect\_p,
.Period\_t)]\\
\>\op{loopsel} [\op{fun}(t:TUPLE) dataSNcar\_BoxNet\_timespace
\op{windowintersectsS}[attr(t, Box)]\\
\>\>\op{sort rdup} dataSNcar \op{gettuples}\\
\>\>\op{filter}[(.Trip \op{atperiods} (attr(t,Period\_t))) \op{passes}
(attr(t,Pos\_p))]\\
\>\>\op{projectextend}[; Id: attr(t,Id\_p), Period: attr(t,Period\_t), Licence:
.Licence]]\\
\>\op{sortby} [Id \op{asc}, Period \op{asc}, Licence \op{asc}]\\
\>\op{krdup} [Id, Period, Licence]\\
\op{consume};\\
\\
\op{let} Q15TBA =\\
\>QueryPoints1Net \op{feed projectextend} [Id, Pos; Prect:
\op{gpoint2rect}(.Pos)] \{p\}\\
\>QueryPeriods1 \op{feed filter}[\op{not}(\op{isempty}(.Period))]\{t\}\\
\>\op{product}\\
\>\op{loopsel}[\op{fun} (t:TUPLE) dataMNtrip\_BoxNet\_timespace
\op{windowintersectsS}[\\
\>\>\>\op{box3d}(attr(t,Prect\_p), attr(t,Period\_t))]\\
\>\>\op{sort rdup} dataMNtrip \op{gettuples}\\
\>\>\op{filter}[(.Trip \op{atperiods} (attr(t,Period\_t))) \op{passes}
(attr(t,Pos\_p))]\\
\>\>\op{projectextend} [Moid;Period: attr(t,Period\_t), Id:
attr(t,Id\_p)]]\{a\}\\
\>\op{loopjoin}[dataMcar\_Moid\_btree dataMcar \op{exactmatch} [.Moid\_a]]\\
\>\op{projectextend} [Licence; Id: .Id\_a, Period: .Period\_a]\\
\>\op{sortby} [Id \op{asc}, Period \op{asc}, Licence \op{asc}]\\
\>\op{krdup}[Id, Period, Licence]\\
\>\op{project}[Licence, Id, Period]\\
\op{consume};\\
\\
\op{let} Q16OBA =\\
\>QueryLicences1 \op{feed} \{l\}\\
\>\>\>\op{loopjoin} [dataSNcar\_Licence\_btree dataSNcar \op{exactmatch}
[.Licence\_l]] \{c\}\\
\>\>QueryPeriods1 \{op{feed filter}[\op{not}(\op{isempty}(.Period))]\{p\}\\
\>\>\op{symmjoin}[.Trip\_c \op{present} ..Period\_p]\\
\>\>\>\op{projectextend}[Id\_p, Period\_p; Licence: .Licence\_c, Trip: .Trip\_c
\op{atperiods} .Period\_p]\\
\>\>\>\op{filter} [\op{no\_components}(.Trip) $>$ 0]\\
\>\>QueryRegions1Net \op{feed filter}[\op{not}(\op{isempty}(.Region))] \{r\}\\
\>\>\op{symmjoin}[.Trip \op{passes} ..Region\_r]\\
\>\>\op{projectextend}[Licence, Id\_r, Region\_r, Id\_p, Period\_p; Trip: .Trip
\op{at} .Region\_r]\\
\>\>\op{filter}[\op{no\_components}(.Trip) $>$ 0]\{a\}\\
\>QueryLicences2 \op{feed} \{l\}\\
\>\>\>\op{loopjoin} [dataSNcar\_Licence\_btree dataSNcar \op{exactmatch}
[.Licence\_l]] \{c\}\\
\>\>QueryPeriods1 \op{feed filter}[\op{not}(\op{isempty}(.Period))]\{p\}\\
\>\>\op{symmjoin} [.Trip\_c \op{present} ..Period\_p]\\
\>\>\>\op{projectextend}[Id\_p, Period\_p; Licence: .Licence\_c, Trip: .Trip\_c
\op{atperiods} .Period\_p]\\
\>\>\>\op{filter} [\op{no\_components}(.Trip) $>$ 0]\\
\>\>QueryRegions1Net \op{feed filter}[\op{not}(\op{isempty}(.Region))]\{r\}\\
\>\>\op{symmjoin}[.Trip \op{passes} ..Region\_r]\\
\>\>\op{projectextend} [Licence, Id\_r, Region\_r, Id\_p, Period\_p; Trip: .Trip
\op{at} .Region\_r]\\
\>\>\op{filter} [\op{no\_components}(.Trip) $>$ 0]\{b\}\\
\>\op{symmjoin}[(.Id\_r\_a = ..Id\_r\_b) \op{and} (.Id\_p\_a = ..Id\_p\_b)]\\
\>\op{filter} [.Licence\_a $\neq$ .Licence\_b]\\
\>\op{filter} [\op{not}(.Trip\_a \op{intersects} .Trip\_b)]\\
\>\op{project} [Id\_r\_a, Period\_p\_a, Licence\_a, Licence\_b]\\
\op{consume};\\
\\
\op{let} Q16TBA =\\
\>QueryLicences1 \op{feed} \{l\}\\
\>\>\>\op{loopjoin} [dataMcar\_Licence\_btree dataMcar
\op{exactmatch}[.Licence\_l]] \{a\}\\
\>\>\>\op{loopjoin}[dataMNtrip\_Moid\_btree dataMNtrip
\op{exactmatch}[.Moid\_a]]\\
\>\>QueryPeriods1 \op{feed filter}[\op{not}(\op{isempty}(.Period))]\{p\}\\
\>\>\op{symmjoin} [.Trip \op{present} ..Period\_p]\\
\>\>\>\op{projectextend}[Id\_p, Period\_p; Licence: .Licence\_a, Trip: .Trip
\op{atperiods} .Period\_p]\\
\>\>\>\op{filter}[\op{no\_components}(.Trip) $>$ 0]\\
\>\>QueryRegions1Net \op{feed filter}[\op{not}(\op{isempty}(.Region))]\{r\}\\
\>\>\op{symmjoin} [.Trip \op{passes} ..Region\_r]\\
\>\>\>\op{projectextend}[Licence, Id\_p, Period\_p, Id\_r; Trip: .Trip \op{at}
.Region\_r]\\
\>\>\>\op{filter} [\op{no\_components} (.Trip) $>$ 0]\{a\}\\
\>QueryLicences2 \op{feed} \{l\}\\
\>\>\>\op{loopjoin} [dataMcar\_Licence\_btree dataMcar
\op{exactmatch}[.Licence\_l]]\{a\}\\
\>\>\>\op{loopjoin}[dataMNtrip\_Moid\_btree dataMNtrip
\op{exactmatch}[.Moid\_a]]\\
\>\>QueryPeriods1 \op{feed filter}[\op{not}(\op{isempty}(.Period))]\{p\}\\
\>\>\op{symmjoin} [.Trip \op{present} ..Period\_p]\\
\>\>\>\op{projectextend}[Id\_p, Period\_p; Licence: .Licence\_a, Trip: .Trip
\op{atperiods} .Period\_p]\\
\>\>\>\op{filter}[\op{no\_components}(.Trip) $>$ 0]\\
\>\>QueryRegions1Net \op{feed filter}[\op{not}(\op{isempty}(.Region))]\{r\}\\
\>\>\op{symmjoin} [.Trip \op{passes} ..Region\_r]\\
\>\>\>\op{projectextend}[Licence, Id\_p, Id\_r; Trip: .Trip \op{at}
.Region\_r]\\
\>\>\>\op{filter} [\op{no\_components} (.Trip) $>$ 0]\{b\}\\
\>\op{symmjoin}[(.Id\_r\_a = ..Id\_r\_b) \op{and} (.Id\_p\_a = ..Id\_p\_b)]\\
\>\op{filter}[.Licence\_a $\neq$ .Licence\_b]\\
\>\op{filter} [\op{not}(.Trip\_a \op{intersects} .Trip\_b)]\\
\>\op{project} [Id\_r\_a, Id\_p\_a, Period\_p\_a, Licence\_a, Licence\_b]\\
\>\op{sortby} [Id\_r\_a \op{asc}, Id\_p\_a \op{asc}, Licence\_a \op{asc},
Licence\_b \op{asc}]\\
\>\op{krdup} [Id\_r\_a, Id\_p\_a, Licence\_a, Licence\_b]\\
\op{consume};\\
\\
\op{let} Q17hOBA =\\
\>dataSNcar \op{feed} \{c\}\\
\>QueryPointsNet \op{feed} \{p\}\\
\>\op{symmjoin} [.Trip\_c \op{passes} ..Pos\_p]\\
\>\op{project} [Id\_p, Licence\_c]\\
\>\op{sortby} [Id\_p, Licence\_c]\\
\>\op{krdup} [Id\_p, Licence\_c]\\
\>\op{groupby}[Id\_p; Hits: \op{group feed count}]\\
\op{consume};\\
\op{let} Q17OBA =\\
\>Q17hOBA \op{feed filter} [.Hits = (Q17hOBA \op{feed max}[Hits])]\\
\>\op{project} [Id\_p, Hits]\\
\op{consume};\\
\op{delete} Q17hOBA;\\
\\
\op{let} Q17hTBA =\\
\>QueryPointsNet \op{feed projectextend}[Id; Elem: \op{gpoint2rect}(.Pos)]\\
\>\op{loopsel}[\op{fun} (t:TUPLE) dataMNtrip\_TrajBoxNet
\op{windowintersectsS}[attr(t,Elem)]\\
\>\>\op{sort rdup} dataMNtrip \op{gettuples}\\
\>\>\op{projectextend} [Moid; Id\_p: attr(t,Id)]]\\
\>\op{sortby} [Id\_p \op{asc}, Moid \op{asc}]\\
\>\op{krdup}[Id\_p, Moid]\\
\>\op{groupby}[Id\_p; Hits: \op{group feed count}]\\
\op{consume};\\
\op{let} Q17TBA =\\
\>Q17hTBA \op{feed filter} [.Hits = (Q17hTBA \op{feed max}[Hits])]\\
\>\op{project} [Id\_p, Hits]\\
\op{consume};\\
\op{delete} Q17hTBA;\\
\end{tabbing}
\end{scriptsize}
\end{document}
